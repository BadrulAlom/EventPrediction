{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\" style=\"background-color:#616161;color:white\">RNN Model</h1>\n",
    "\n",
    "Adapted from: https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">0. Setup</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Input Parameters</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Root path\n",
    "#root = \"C:/DS/Github/MusicRecommendation\"  # BA, Windows\n",
    "root = \"/home/badrul/git/EventPrediction\" # BA, Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Common Libraries</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
<<<<<<< HEAD
    "collapsed": true,
=======
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.debugger import Tracer    # Used for debugging\n",
    "import logging\n",
    "from random import *\n",
    "\n",
    "# File and database management\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "# Date/Time\n",
    "import datetime\n",
    "import time\n",
    "#from datetime import timedelta # Deprecated\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt             # Quick\n",
    "%matplotlib inline\n",
    "\n",
    "# Misc\n",
    "import random\n",
    "import importlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.basicConfig(filename='RNN.log',level=logging.DEBUG)\n",
    "\n",
    "#-------------- Custom Libs -----------------#\n",
    "os.chdir(root)\n",
    "\n",
    "# Import the codebase module\n",
    "fPath = root + \"/1_codemodule\"\n",
    "if fPath not in sys.path: sys.path.append(fPath)\n",
    "\n",
    "# Custom Libs\n",
    "import coreCode as cc\n",
    "import lastfmCode as fm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Page Specific Libraries</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
<<<<<<< HEAD
    "collapsed": true,
=======
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data science (comment out if not needed)\n",
    "#from sklearn.manifold import TSNE\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Load settings</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "settingsDict =  cc.loadSettings()\n",
    "dbPath = root + settingsDict['mainDbPath_xsml']\n",
    "fmSimilarDbPath = root + settingsDict['fmSimilarDbPath']\n",
    "fmTagsDbPath = root + settingsDict['fmTagsDbPath']\n",
    "trackMetaDbPath = root + settingsDict['trackmetadata']\n",
    "periodGranularity = int(settingsDict['periodGranularity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "<h4 style=\"background-color:#616161;color:white\">Model Parameters</h4>"
=======
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Set parameters</div>"
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "# Model setup\n",
    "loadFromSave = False\n",
    "trainModel = 1 # Which RNN model to use    \n",
    "\n",
    "################# MODEL 1 ##################\n",
    "if trainModel == 1:\n",
    "    sample_iteration = 2  # How many iterations of user selection\n",
    "    numOfPeriods = 1000   # How many periods to select in each sample_iteration\n",
    "    training_iterations = 50  # How many iterations of the selected periods\n",
    "    batch_size = 1000       # For every random period selected, how many prior periods do we want to train at the same time\n",
    "    n_steps = 336         # How many time steps (i.e. depth) to have\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    n_hidden = 160 # hidden layer num of features\n",
    "    n_classes = 2  # 2 for one-hot\n",
    "    cellType = \"BasicLSTMCell\"  # Choose: TimeFreqLSTMCell BasicLSTMCell\n",
    "\n",
    "################# MODEL 2 ##################\n",
    "elif trainModel == 2:\n",
    "    sample_iteration = 2\n",
    "    n_steps = 1 # has to be 1\n",
    "    batch_size = 1\n",
    "    training_iterations = 10\n",
    "    learning_rate = 0.001\n",
    "    n_hidden = 160 # hidden layer num of features\n",
    "    n_classes = 2\n",
    "    cellType = \"BasicLSTMCell\"  # Choose: TimeFreqLSTMCell BasicLSTMCell\n",
    "    \n",
    "# Training parameters\n",
=======
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model setup\n",
    "loadFromSave = False\n",
    "n_steps = 336 # timesteps\n",
    "n_hidden = 160 # hidden layer num of features\n",
    "n_classes = 2\n",
    "batch_size = 336*4\n",
    "learning_rate = 0.001\n",
    "cellType = \"BasicLSTMCell\"  # Choose: TimeFreqLSTMCell BasicLSTMCell\n",
    "\n",
    "#fieldList=\"UserID, t, HrsFrom5pm, isSun,isMon,isTue,isWed,isThu,isFri,isSat, t1,t2,t3,t4,t5,t10,t12hrs,t23_5hrs,t24hrs,t24_5hrs,t1wk,t2wks,t3wks,t4wks\"\n",
    "fieldList=\"UserID, t, HrsFrom5pm, isSun,isMon,isTue,isWed,isThu,isFri,isSat, t10,t12hrs,t24hrs,t1wk,t2wks,t3wks,t4wks\"\n",
    "\n",
    "# Training parameters\n",
    "training_iterations = 1\n",
    "sample_iteration = 1\n",
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
    "display_step = 5\n",
    "userSample =1\n",
    "timeStepSkip =5000\n",
    "\n",
<<<<<<< HEAD
    "# Dummy test\n",
    "dummyTest = False\n",
    "if dummyTest: \n",
    "    tblName='tblTimeSeriesDataDummy'  # 'tblName='tblTimeSeriesDataDummy'\n",
    "    fieldList=\"UserID, t, HrsFrom5pm, isSun,isMon,isTue,isWed,isThu,isFri,isSat,t1wk,t2wks,t3wks,t4wks\"\n",
    "else:\n",
    "    #fieldList=\"UserID, t, HrsFrom5pm, isSun,isMon,isTue,isWed,isThu,isFri,isSat, t1,t2,t3,t4,t5,t10,t12hrs,t23_5hrs,t24hrs,t24_5hrs,t1wk,t2wks,t3wks,t4wks\"\n",
    "    tblName='tblTimeSeriesData'  # 'tblName='tblTimeSeriesDataDummy'\n",
    "    fieldList=\"UserID, t, HrsFrom5pm, isSun,isMon,isTue,isWed,isThu,isFri,isSat, t10,t12hrs,t24hrs,t1wk,t2wks,t3wks,t4wks\"\n",
    "\n",
    "print('Ok')"
=======
    "tblName='tblTimeSeriesData'  # 'tblName='tblTimeSeriesDataDummy'\n",
    "trainModel = 1\n",
    "\n",
    "# Dummy test\n",
    "dummyTest = True\n",
    "if dummyTest: \n",
    "    tblName='tblTimeSeriesDataDummy'  # 'tblName='tblTimeSeriesDataDummy'\n",
    "    fieldList=\"UserID, t, HrsFrom5pm, isSun,isMon,isTue,isWed,isThu,isFri,isSat,t1wk,t2wks,t3wks,t4wks\"\n",
    "    trainModel = 1  # Which RNN model to use\n",
    "    n_steps = 5 # has to be 1 for train model 2\n",
    "    batch_size = 5  # Num of 'time steps' in model 2\n",
    "    training_iterations = 10"
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">1. Build Model</h3>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
=======
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
   "source": [
    "def RNN(x, weights, biases,n_steps):\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "    \n",
    "    # Unstack to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
<<<<<<< HEAD
    "    if (trainModel == 1) or (trainModel == 3):\n",
=======
    "    if trainModel == 1:\n",
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
    "        x = tf.unstack(x, n_steps, 1)  # See https://stackoverflow.com/questions/45278276/tensorflow-lstm-dropout-implementation-shape-problems/45279243#45279243\n",
    "    elif trainModel == 2:\n",
    "        x = tf.unstack(x, batch_size, 0)\n",
    "    \n",
    "    # Define a lstm cell with tensorflow\n",
    "    #lstm_cell = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "    if cellType == \"BasicLSTMCell\":\n",
    "        lstm_cell = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "        outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    elif cellType == \"TimeFreqLSTMCell\":\n",
    "        lstm_cell =rnn.TimeFreqLSTMCell(n_hidden, use_peepholes=True, feature_size= 22, forget_bias=1.0)\n",
    "        outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    elif cellType == \"GridLSTMCell\":\n",
    "        lstm_cell =rnn.GridLSTMCell(n_hidden, forget_bias=1.0)\n",
    "        outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)        \n",
    "    else:\n",
    "        print(\"Did not recognize {}\".format(cellType))\n",
    "    # Get lstm cell output\n",
    "    \n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
<<<<<<< HEAD
    "##########################################################################\n",
    "\n",
    "def buildGraph(n_steps,n_input, classWeights = None):\n",
    "    global x, y, pred, predProb, test, _logits, cost, optimizer,accuracy, c0_error, c1_error\n",
=======
    "def buildGraph(n_steps,n_input):\n",
    "    global x, y, pred, cost, optimizer,accuracy\n",
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
    "    \n",
    "    tf.reset_default_graph()\n",
    "    # tf Graph input\n",
    "    \n",
    "    x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "    y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "    # Define weights\n",
<<<<<<< HEAD
    "    weights = {'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))}\n",
    "    biases = {'out': tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "    # Evaluate model\n",
    "    if n_classes>1:  # If multi-class\n",
    "        _logits = RNN(x, weights, biases,n_steps)\n",
    "        \n",
    "        # Class 0\n",
    "        c0_w = [0,0]\n",
    "        c0_weightedLogits =tf.multiply(_logits, c0_w)\n",
    "        c0_y = tf.multiply(y, c0_w)\n",
    "        c0_error = tf.nn.softmax_cross_entropy_with_logits(logits=c0_weightedLogits, labels=c0_y)\n",
    "        \n",
    "        # Class 1\n",
    "        c1_w = [0,1]\n",
    "        c1_weightedLogits =tf.multiply(_logits, c1_w)\n",
    "        c1_y = tf.multiply(y, c1_w)\n",
    "        c1_error = tf.nn.softmax_cross_entropy_with_logits(logits=c1_weightedLogits, labels=c1_y)\n",
    "        \n",
    "        _weightedLogits=tf.add(c0_weightedLogits,c1_weightedLogits)\n",
    "        \n",
    "        #_weightedLogits =tf.multiply(_logits, classWeights)\n",
    "        #error = tf.nn.softmax_cross_entropy_with_logits(logits=_weightedLogits, labels=y)\n",
    "        #cost = tf.reduce_mean(error)\n",
    "        \n",
    "        cost = tf.reduce_mean(tf.add(c0_error,c1_error))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)    \n",
    "        predProb = tf.nn.softmax(_weightedLogits)\n",
    "        pred = tf.argmax(predProb,1)\n",
    "        correct_pred = tf.equal(pred, tf.argmax(y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        \n",
    "    else:\n",
    "        # Let's use a different activation function here\n",
    "        _logits = RNN(x, weights, biases,n_steps)\n",
    "            \n",
    "        test = tf.sigmoid(_logits)\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=_logits, labels=y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "        \n",
    "        predProb =tf.nn.softmax(_logits)\n",
    "        pred =tf.round(predProb)\n",
    "        correct_pred = tf.equal(pred, y)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "print('Ok')"
=======
    "    weights = {\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "\n",
    "    pred = RNN(x, weights, biases,n_steps)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Evaluate model\n",
    "    correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
=======
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
   "source": [
    "n_input = len(fieldList.split(\",\"))-2 # -2 as we drop UserID and t\n",
    "\n",
    "# Build graph\n",
<<<<<<< HEAD
    "w = [0.05,1.5]\n",
    "buildGraph(n_steps,n_input = n_input,classWeights=w)\n",
=======
    "buildGraph(n_steps,n_input = n_input)\n",
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
    "# Initializing the variables\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "if loadFromSave:\n",
    "    saver.restore(sess,'./3_Data/saves/model.ckpt')\n",
    "else:\n",
<<<<<<< HEAD
    "    sess.run(init)\n",
    "print('Ok')"
=======
    "    sess.run(init)"
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">2. Train Model</h3>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "metadata": {
=======
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
    "scrolled": true
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "##############################################\n",
    "###           TRAIN MODEL 2                ###\n",
    "##############################################\n",
=======
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
    "# Launch the graph\n",
    "def trainModel2(_X, _Y, sess,training_iterations = 5):\n",
    "    # Training cycle\n",
    "    l=np.shape(_X)[0]\n",
    "    predictions=np.zeros([l,n_classes])\n",
    "    idx=0\n",
    "    \n",
    "    for i in range(training_iterations):\n",
    "        if (training_iterations % 10) == 0: print(\"Now on iteration {}\".format(i))\n",
    "        #logging.info(\"Now on iteration {}\".format(i))\n",
    "        # Loop over all rows in order of earliest to latest\n",
    "        for pos in range(0+batch_size, l,3):\n",
    "            if (pos % 1000) == 0: \n",
    "                print(\"Now on pos {} of {} ({}%)\".format(pos,l,round((pos/l)*100,2)))\n",
    "                logging.info(\"Now on pos {} of {} ({}%)\".format(pos,l,round((pos/l)*100,2)))\n",
    "            \n",
    "            # For each row, collect the previous batch_size num of rows\n",
    "            batch_x = _X[pos-batch_size:pos].reshape((batch_size, n_steps, n_input)) \n",
    "            batch_y = _Y[pos].reshape((-1, n_classes)) \n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "            # Test at the same time\n",
<<<<<<< HEAD
    "            p = sess.run(predProb, feed_dict={x: batch_x, y: batch_y})\n",
=======
    "            p = sess.run(pred, feed_dict={x: batch_x, y: batch_y})\n",
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
    "            predictions[idx]=p=p.reshape(-1,n_classes)[-1]\n",
    "            \n",
    "    \n",
    "        # Calculate loss & accuracy\n",
    "        acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "        loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "        \n",
    "        predictions = np.argmax(predictions,1).reshape(-1,1)\n",
    "        labels=np.argmax(_Y,1).reshape(-1,1)\n",
    "        \n",
    "        print (\"Iter {}. Minibatch Loss={:.6f}\".format(i, loss) + \", Training Accuracy= \" + \"{:.5f}\".format(acc))\n",
<<<<<<< HEAD
    "        \n",
=======
    "        Tracer()()\n",
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
    "        print(metrics.classification_report(labels,predictions))  # Need to feed it yTest not yTest_OneHot here"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "###           TRAIN MODEL 1                ###\n",
    "##############################################\n",
=======
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
    "# Launch the graph\n",
    "def trainModel1(_X, _Y, sess,_iterations = 5, numOfPeriods = 10, trainPeriods = None):\n",
    "    # Num of periodss = batch size\n",
    "    \n",
    "    # Training cycle\n",
    "    totalRows=np.shape(_X)[0]\n",
    "    XCols=np.shape(_X)[1]\n",
    "    YCols=np.shape(_Y)[1]\n",
    "    depth = n_steps\n",
    "    \n",
    "    # If no trainPeriods were provided generate your own\n",
    "    if trainPeriods is None:\n",
    "        # Select periods where we will always get enough history to go with it\n",
    "        trainPeriods = random.sample(range(batch_size+depth, totalRows), numOfPeriods)\n",
    "    else:\n",
<<<<<<< HEAD
    "        trainPeriods = trainPeriods + batch_size+depth-1  # Offset trainPeriods so [0,4,6] => [0+..,4+..,6+..]\n",
    "        numOfPeriods = len(trainPeriods)\n",
    "    \n",
    "    for i in range(_iterations):\n",
=======
    "        trainPeriods = trainPeriods + batch_size+depth-1\n",
    "        numOfPeriods = len(trainPeriods)\n",
    "    \n",
    "    \n",
    "    for i in range(_iterations):\n",
    "        if (_iterations % 1) == 0: print(\"Now on iteration {}\".format(i))\n",
    "        #logging.info(\"Now on iteration {}\".format(i))\n",
    "        \n",
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
    "        # Pre-Initialize batch arrays\n",
    "        batch_x=np.zeros([numOfPeriods,depth,XCols])\n",
    "        batch_y=np.zeros([numOfPeriods,YCols])\n",
    "        \n",
    "        batch_row =0\n",
    "        for idx1 in trainPeriods:            \n",
    "            # Each period will have one batch\n",
    "            # Logging\n",
    "            if (idx1 % 1) == 0: \n",
    "                timeNow =str(datetime.datetime.now())\n",
    "                #print(\"{} Now training on Period {} ({}%)\".format(timeNow,idx1,round((batch_row/numOfPeriods)*100,2)))\n",
    "                logging.info(\"{} Now training on Period {} ({}%)\".format(timeNow, idx1,round((batch_row/numOfPeriods)*100,2)))\n",
    "\n",
<<<<<<< HEAD
    "            # READ DATA FROM THE INPUT PROVIDED AND BUILD UP THE BATCH\n",
=======
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
    "            batch_x[batch_row] = _X[idx1-depth:idx1].reshape(1,depth,XCols)\n",
    "            batch_y[batch_row] = _Y[idx1]\n",
    "            batch_row +=1\n",
    "            \n",
<<<<<<< HEAD
    "        \n",
    "        # Train   \n",
    "        #Only train on samples that contain at least 1 listen in the last batch_size periods\n",
    "        if (sum(batch_y[1]) == 0):\n",
    "            print ('Batch skipped as no plays')\n",
    "        else:\n",
    "            batch_y = batch_y.reshape((-1, YCols))\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        if (i % 10) == 0: \n",
    "            # Calculate loss & accuracy\n",
    "            c0loss = sess.run(c0_error,feed_dict={x: batch_x, y: batch_y})\n",
    "            c1loss = sess.run(c1_error,feed_dict={x: batch_x, y: batch_y})        \n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "            s=\"Iter {}. Minibatch Loss={:.6f}, Training Accuracy={:.5f}, Class 0 loss {}, Class 1 loss {}\".format(i, loss, acc,np.mean(c0loss), np.mean(c1loss))\n",
    "            print(s)\n",
    "            logging.info(s)\n",
    "           \n",
    "    predictions = sess.run(pred, feed_dict={x: batch_x, y: batch_y}).reshape(-1,1)\n",
    "    logits= sess.run(_logits, feed_dict={x: batch_x, y: batch_y}).reshape(-1,1)\n",
    "    prob= sess.run(predProb, feed_dict={x: batch_x, y: batch_y}).reshape(-1,1)\n",
    "    batch_y = np.argmax(batch_y,1).reshape(-1,1)\n",
    "    print(metrics.classification_report(batch_y,predictions))  # Need to feed it yTest not yTest_OneHot here\n",
=======
    "         # Train\n",
    "        batch_y = batch_y.reshape((-1, YCols))\n",
    "        \n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        \n",
    "        # Calculate train accuracy\n",
    "        #idx1 = randint(0+batch_size+depth, totalRows)  # Randomly select a pos in the current dataset\n",
    "        #batch_y = _Y[idx1-batch_size:idx1]                        \n",
    "        #batch_x = _X[idx1-batch_size:idx1]\n",
    "        #batch_x = batch_x.reshape((batch_size, 1, XCols))  # Rehsape into 3d\n",
    "        \n",
    "        #for idx2 in range(idx1-1,idx1-depth,-1):\n",
    "        #        slice_x = _X[idx2-batch_size:idx2].reshape(batch_size,1,XCols) \n",
    "        #        batch_x=np.append(batch_x,slice_x, axis=1)    \n",
    "        #batch_y = batch_y.reshape((-1, YCols))\n",
    "        \n",
    "        # Calculate loss & accuracy\n",
    "        acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "        loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "        print (\"Iter {}. Minibatch Loss={:.6f}\".format(i, loss) + \", Training Accuracy= \" + \"{:.5f}\".format(acc))\n",
    "        \n",
    "        predictions = 1*sess.run(pred, feed_dict={x: batch_x, y: batch_y})\n",
    "        predictions = np.argmax(predictions,1).reshape(-1,1)\n",
    "        batch_y = np.argmax(batch_y,1).reshape(-1,1)\n",
    "        print(metrics.classification_report(batch_y,predictions))  # Need to feed it yTest not yTest_OneHot here\n",
    "        TestHiddenPeriods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-08 00:48:26.180112 Now processing sample 0\n",
      "2017-08-08 00:48:26.183845 Now processing User 3\n",
      "Now on iteration 0\n",
      "Iter 0. Minibatch Loss=0.731915, Training Accuracy= 0.80000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88         8\n",
      "          1       0.50      0.50      0.50         2\n",
      "\n",
      "avg / total       0.80      0.80      0.80        10\n",
      "\n",
      "Now on iteration 1\n",
      "Iter 1. Minibatch Loss=0.714610, Training Accuracy= 0.80000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89         8\n",
      "          1       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.64      0.80      0.71        10\n",
      "\n",
      "Now on iteration 2\n",
      "Iter 2. Minibatch Loss=0.749949, Training Accuracy= 0.80000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89         8\n",
      "          1       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.64      0.80      0.71        10\n",
      "\n",
      "Now on iteration 3\n",
      "Iter 3. Minibatch Loss=0.787473, Training Accuracy= 0.80000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89         8\n",
      "          1       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.64      0.80      0.71        10\n",
      "\n",
      "Now on iteration 4\n",
      "Iter 4. Minibatch Loss=0.798857, Training Accuracy= 0.80000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89         8\n",
      "          1       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.64      0.80      0.71        10\n",
      "\n",
      "Now on iteration 5\n",
      "Iter 5. Minibatch Loss=0.777413, Training Accuracy= 0.80000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89         8\n",
      "          1       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.64      0.80      0.71        10\n",
      "\n",
      "Now on iteration 6\n",
      "Iter 6. Minibatch Loss=0.728870, Training Accuracy= 0.80000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89         8\n",
      "          1       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.64      0.80      0.71        10\n",
      "\n",
      "Now on iteration 7\n",
      "Iter 7. Minibatch Loss=0.667571, Training Accuracy= 0.80000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89         8\n",
      "          1       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.64      0.80      0.71        10\n",
      "\n",
      "Now on iteration 8\n",
      "Iter 8. Minibatch Loss=0.613253, Training Accuracy= 0.90000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94         8\n",
      "          1       1.00      0.50      0.67         2\n",
      "\n",
      "avg / total       0.91      0.90      0.89        10\n",
      "\n",
      "Now on iteration 9\n",
      "Iter 9. Minibatch Loss=0.581102, Training Accuracy= 0.80000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88         8\n",
      "          1       0.50      0.50      0.50         2\n",
      "\n",
      "avg / total       0.80      0.80      0.80        10\n",
      "\n",
      "100 Hidden Periods\n",
      "\n",
      "Cell type= BasicLSTMCell, learning_rate = 0.001, Iterations = 10, batch size = 5, Steps = 5, Hidden Layers = 160, Classes = 2\n",
      "\n",
      "(100, 1) (100, 1)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.97      0.80        67\n",
      "          1       0.50      0.06      0.11        33\n",
      "\n",
      "avg / total       0.62      0.67      0.57       100\n",
      "\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "## Begin training\n",
    "numOfPeriods =20\n",
    "\n",
    "for s in range(sample_iteration):\n",
    "    timeNow =str(datetime.datetime.now())\n",
    "    print('{} Now processing sample {}'.format(timeNow,s))\n",
    "    logging.info('{} Now processing sample {}'.format(timeNow, s))\n",
    "    \n",
    "    if dummyTest:\n",
    "        users = pd.DataFrame(data={'userID': [3]})\n",
    "    else:\n",
    "        users=cc.getUsers(dbPath).sample(userSample)\n",
    "        \n",
    "    for usr in users.itertuples():\n",
    "        timeNow =str(datetime.datetime.now())\n",
    "        print('{} Now processing User {}'.format(timeNow, usr.userID))\n",
    "        logging.info('{} Now processing User {}'.format(timeNow, usr.userID))\n",
    "        xTrain, yTrain_onehot, xTest, yTest_onehot = cc.getHiddenPeriodsData(dbPath,tblName,fieldList,oneHot=True,periodGranularity=periodGranularity,userIDs=[usr.userID])\n",
    "        \n",
    "        if xTrain is not None:\n",
    "            if np.shape(yTrain_onehot)[1] !=1:  # Results have to have both 0's and 1's in them\n",
    "                if trainModel ==1:\n",
    "                    #trainModel1(xTrain, yTrain_onehot, sess,training_iterations, numOfPeriods=numOfPeriods)\n",
    "                    trainModel1(xTrain, yTrain_onehot, sess,training_iterations)\n",
    "                elif trainModel ==2:\n",
    "                    trainModel2(xTrain, yTrain_onehot, sess,training_iterations)\n",
    "        saver.save(sess,\"./3_Data/saves/model.ckpt\")\n",
    "\n",
    "TestHiddenPeriods()       \n",
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
    "print('Ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
=======
    "<h3 style=\"background-color:blue;color:white\"></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
    "<h3 style=\"background-color:#616161;color:white\">3. Test Model</h3>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 21,
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def TestPredictions2(_X,_Y,sess):\n",
    "    \n",
    "    l=np.shape(_X)[0]\n",
    "    labels=np.zeros([l,n_classes]) # Calculate the number of lead Y's we will end up with\n",
    "    predictions=np.zeros([l,n_classes])\n",
    "    \n",
    "    # Testing cycle\n",
    "    print(\"Now testing {} rows\".format(l))\n",
    "    logging.info(\"Now testing {} rows\".format(l))\n",
    "    \n",
    "    # Pad rows at the beginning so we can get a prediction for every entry\n",
    "    padX=np.zeros([batch_size-1,_X.shape[1]])\n",
    "    _Y = _Y.reshape(-1,n_classes)\n",
    "    padY=np.zeros([batch_size-1,n_classes])\n",
    "    \n",
    "    _X = np.append(padX, _X, axis=0)\n",
    "    _Y = np.append(padY, _Y, axis=0)\n",
    "    l=np.shape(_X)[0]  # Update length\n",
    "    \n",
    "    # Pre allocate arrays and regain sanity\n",
    "    idx =0\n",
    "    for pos in range(0+batch_size, l):\n",
    "        \n",
    "        if (pos % 10000) == 0: \n",
    "            print(\"Now on pos {} of {} ({}%)\".format(pos,l,round((pos/l)*100,2)))\n",
    "            #logging.info(\"Now on pos {} of {} ({}%)\".format(pos,l,round((pos/l)*100,2)))\n",
    "\n",
    "        # For each row, collect the previous batch_size num of rows\n",
    "        batch_x = _X[pos-batch_size:pos]\n",
    "        batch_y = _Y[pos]\n",
    "        #if np.mod(len(batch_x),batch_size) == 0:batch_x, batch_y, _ = cc.padRows(batch_x, batch_y, batch_size)\n",
    "        batch_x = batch_x.reshape((batch_size, n_steps, n_input))  # Rehsape into 3d, even though n_steps is 1            \n",
    "        batch_y = batch_y.reshape((-1, n_classes))  # Rehsape into 3d, even though n_steps is 1            \n",
    "\n",
    "        # Predict!\n",
    "        p = 1*sess.run(pred, feed_dict={x: batch_x})\n",
    "        p=p.reshape(-1,n_classes)\n",
    "        \n",
    "        #print(_Y[pos], batch_y)\n",
    "        predictions[idx] = p[-1]\n",
    "        labels[idx] = batch_y[-1]\n",
    "        idx+=1\n",
    "    \n",
    "    \n",
    "    # Remove padding and return predictions\n",
    "    predictions = np.argmax(predictions,1)\n",
    "    predictions = predictions.reshape(-1,1)\n",
    "    labels = np.argmax(labels,1)\n",
    "    labels = labels.reshape(-1,1)\n",
    "    \n",
    "    return predictions, labels"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 25,
   "metadata": {},
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
   "outputs": [],
   "source": [
    "# Launch the graph\n",
    "def TestPredictions1(_X, _Y, sess, numOfPeriods = 10, testPeriods = None):\n",
    "    # Training cycle\n",
    "    totalRows=np.shape(_X)[0]\n",
    "    XCols=np.shape(_X)[1]\n",
    "    YCols=np.shape(_Y)[1]\n",
    "    depth = n_steps\n",
    "    \n",
    "    # If no test periods were provided generate your own\n",
    "    if testPeriods is None:\n",
    "        # Select periods where we will always get enough history to go with it\n",
    "        testPeriods = random.sample(range(batch_size+depth, totalRows), numOfPeriods)\n",
    "    else:\n",
    "        testPeriods = testPeriods + batch_size+depth-1\n",
    "        numOfPeriods = len(testPeriods)\n",
    "     \n",
    "    # Pre-Initialize batch arrays\n",
    "    batch_x=np.zeros([numOfPeriods,depth,XCols])\n",
    "    batch_y=np.zeros([numOfPeriods,YCols])\n",
    "\n",
    "    batch_row =0\n",
    "    for idx1 in testPeriods:            \n",
    "        if (idx1 % 1) == 0: \n",
    "            timeNow =str(datetime.datetime.now())\n",
    "            #print(\"{} Now testing on period {} ({}%)\".format(timeNow,idx1,round((batch_row/numOfPeriods)*100,2)))\n",
    "            logging.info(\"{} Now testing period {} ({}%)\".format(timeNow, idx1,round((batch_row/numOfPeriods)*100,2)))\n",
    "\n",
    "        batch_x[batch_row] = _X[idx1-depth:idx1].reshape(1,depth,XCols)\n",
    "        batch_y[batch_row] = _Y[idx1]\n",
    "        batch_row +=1\n",
<<<<<<< HEAD
    "    \n",
    "    \n",
    "    print (\"Processed {}\".format(numOfPeriods))\n",
    "    # Predict for this period\n",
    "    prob = sess.run(predProb, feed_dict={x: batch_x, y: batch_y}).reshape(-1,1)\n",
    "    predictions = sess.run(pred, feed_dict={x: batch_x, y: batch_y}).reshape(-1,1)\n",
    "    batch_y = np.argmax(batch_y,1).reshape(-1,1)\n",
    "\n",
    "    return predictions, batch_y\n",
    "\n"
=======
    "\n",
    "    # Predict for this period\n",
    "    predictions = 1*sess.run(pred, feed_dict={x: batch_x, y: batch_y})\n",
    "    predictions = np.argmax(predictions,1).reshape(-1,1)\n",
    "    batch_y = np.argmax(batch_y,1).reshape(-1,1)\n",
    "    return predictions, batch_y"
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Test hidden periods</div>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
=======
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Hidden Periods\n",
      "\n",
      "Cell type= BasicLSTMCell, learning_rate = 0.001, Iterations = 10, batch size = 5, Steps = 5, Hidden Layers = 160, Classes = 2\n",
      "\n",
      "(100, 1) (100, 1)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.88      0.73        64\n",
      "          1       0.27      0.08      0.13        36\n",
      "\n",
      "avg / total       0.50      0.59      0.51       100\n",
      "\n"
     ]
    }
   ],
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
   "source": [
    "def TestHiddenPeriods(hiddenTestPeriods=50):\n",
    "\n",
    "    print('{} Hidden Periods\\n'.format(hiddenTestPeriods))\n",
    "    print (\"Cell type= {}, learning_rate = {}, Iterations = {}, batch size = {}, Steps = {}, Hidden Layers = {}, Classes = {}\\n\".format(cellType,learning_rate,training_iterations,batch_size, n_steps ,n_hidden,n_classes))\n",
    "\n",
<<<<<<< HEAD
    "    if (trainModel == 1):\n",
    "        predictions,labels = TestPredictions1(xTrain,yTrain,sess,numOfPeriods=hiddenTestPeriods)\n",
    "    elif trainModel == 2:\n",
    "        predictions,labels = TestPredictions2(xTrain,yTrain,sess)\n",
=======
    "    if trainModel == 1:\n",
    "        predictions,labels = TestPredictions1(xTrain,yTrain_onehot,sess,numOfPeriods=hiddenTestPeriods)\n",
    "    elif trainModel == 2:\n",
    "        predictions,labels = TestPredictions2(xTrain,yTrain_onehot,sess)\n",
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
    "\n",
    "    predictions = predictions.reshape(-1,1)\n",
    "    labels = labels.reshape(-1,1)\n",
    "\n",
    "    print(np.shape(labels),np.shape(predictions))    \n",
<<<<<<< HEAD
    "    print(metrics.classification_report(labels,predictions))  # Need to feed it yTest not yTest_OneHot here"
=======
    "    print(metrics.classification_report(labels,predictions))  # Need to feed it yTest not yTest_OneHot here\n",
    "\n",
    "TestHiddenPeriods()"
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "<h3 style=\"background-color:green;color:white\">4. ...And action!</h3>"
=======
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Test hidden users</div>"
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-09 13:23:36.322450 Now processing sample 0\n",
      "2017-08-09 13:23:36.333456 Now processing User 42\n",
      "Iter 0. Minibatch Loss=0.015069, Training Accuracy=0.99600, Class 0 loss 0.0, Class 1 loss 0.015068572014570236\n",
      "Iter 10. Minibatch Loss=0.019526, Training Accuracy=0.99600, Class 0 loss 0.0, Class 1 loss 0.019526146352291107\n",
      "Iter 20. Minibatch Loss=0.020747, Training Accuracy=0.99600, Class 0 loss 0.0, Class 1 loss 0.02074684575200081\n",
      "Iter 30. Minibatch Loss=0.019431, Training Accuracy=0.99600, Class 0 loss 0.0, Class 1 loss 0.019431261345744133\n",
      "Iter 40. Minibatch Loss=0.017611, Training Accuracy=0.99600, Class 0 loss 0.0, Class 1 loss 0.01761062815785408\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       996\n",
      "          1       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.99      1.00      0.99      1000\n",
      "\n",
      "2017-08-09 13:36:11.624794 Now processing sample 1\n",
      "2017-08-09 13:36:11.628220 Now processing User 43\n",
      "Iter 0. Minibatch Loss=0.102235, Training Accuracy=0.98100, Class 0 loss 0.0, Class 1 loss 0.10223469883203506\n",
      "Iter 10. Minibatch Loss=0.064839, Training Accuracy=0.97900, Class 0 loss 0.0, Class 1 loss 0.06483915448188782\n",
      "Iter 20. Minibatch Loss=0.067011, Training Accuracy=0.98000, Class 0 loss 0.0, Class 1 loss 0.06701052188873291\n",
      "Iter 30. Minibatch Loss=0.068739, Training Accuracy=0.98100, Class 0 loss 0.0, Class 1 loss 0.06873908638954163\n",
      "Iter 40. Minibatch Loss=0.060033, Training Accuracy=0.98000, Class 0 loss 0.0, Class 1 loss 0.06003304570913315\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       981\n",
      "          1       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.96      0.98      0.97      1000\n",
      "\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "###           TRAIN                        ###\n",
    "##############################################\n",
    "\n",
    "#training_iterations = 100\n",
    "for s in range(sample_iteration):\n",
    "    timeNow =str(datetime.datetime.now())\n",
    "    print('{} Now processing sample {}'.format(timeNow,s))\n",
    "    logging.info('{} Now processing sample {}'.format(timeNow, s))\n",
    "    \n",
    "    if dummyTest:\n",
    "        users = pd.DataFrame(data={'userID': [3]})\n",
    "    else:\n",
    "        users=cc.getUsers(dbPath).sample(userSample)\n",
    "        \n",
    "    for usr in users.itertuples():\n",
    "        timeNow =str(datetime.datetime.now())\n",
    "        print('{} Now processing User {}'.format(timeNow, usr.userID))\n",
    "        logging.info('{} Now processing User {}'.format(timeNow, usr.userID))\n",
    "        \n",
    "        xTrain, yTrain, xTest, yTest = cc.getHiddenPeriodsData(dbPath,tblName,fieldList,oneHot=(n_classes >1),periodGranularity=periodGranularity,userIDs=[usr.userID])\n",
    "        \n",
    "        if xTrain is not None:\n",
    "            if np.shape(yTrain)[1] ==n_classes:  # Results have to have both 0's and 1's in them\n",
    "                if (trainModel ==1):\n",
    "                    trainModel1(xTrain, yTrain, sess,training_iterations, numOfPeriods=numOfPeriods)\n",
    "                elif trainModel ==2:\n",
    "                    trainModel2(xTrain, yTrain, sess,training_iterations)\n",
    "        else:\n",
    "            print('Skipping user {} as no data'.format(usr.userID))\n",
    "        saver.save(sess,\"./3_Data/saves/model.ckpt\")\n",
    "\n",
    "print('Ok')"
=======
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get hidden users\n",
    "users=cc.getUsers(dbPath).sample(2)\n",
    "u=users.userID.values\n",
    "_,_,xTest, yTest_onehot = cc.getHiddenPeriodsData(dbPath,tblName,fieldList,oneHot=True,periodGranularity=periodGranularity,userIDs=u)\n",
    "print ('{} users selected for testing. Total rows {}'.format(len(u), len(xTest)))\n",
    "\n",
    "xTest2, yTest2_onehot, testDf2 = cc.getHiddenUsersData(dbPath,tblName,fieldList,oneHot= True,firstNPerc=0.5,periodGranularity=periodGranularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('\\nHidden Users')\n",
    "predictions = getTestPredictions(xTest2,yTest2_onehot)\n",
    "print(metrics.classification_report(yTest2_onehot[:,1],predictions))  # Need to feed it yTest not yTest_OneHot here\n",
    "print(np.shape(xTest2),np.shape(yTest2_onehot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">Appendices</h3>"
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Test</div>"
=======
    "<h4 style=\"background-color:#616161;color:white\">Results</h4>"
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #### Validation data test ###\n",
      "50 Hidden Periods\n",
      "\n",
      "Cell type= BasicLSTMCell, learning_rate = 0.001, Iterations = 50, batch size = 1000, Steps = 336, Hidden Layers = 160, Classes = 2\n",
      "\n",
      "Processed 50\n",
      "(50, 1) (50, 1)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        43\n",
      "          1       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.74      0.86      0.80        50\n",
      "\n",
      "50 Hidden Periods\n",
      "\n",
      "Cell type= BasicLSTMCell, learning_rate = 0.001, Iterations = 50, batch size = 1000, Steps = 336, Hidden Layers = 160, Classes = 2\n",
      "\n",
      "Processed 50\n",
      "(50, 1) (50, 1)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94        44\n",
      "          1       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.77      0.88      0.82        50\n",
      "\n",
      " #### Test data test ###\n",
      "20 Hidden Periods\n",
      "\n",
      "Cell type= BasicLSTMCell, learning_rate = 0.001, Iterations = 50, batch size = 1000, Steps = 336, Hidden Layers = 160, Classes = 2\n",
      "\n",
      "Processed 20\n",
      "(20, 1) (20, 1)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89        16\n",
      "          1       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.64      0.80      0.71        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation data test\n",
    "\n",
    "print(' #### Validation data test ###')\n",
    "# Randomly select users from the train sample\n",
    "users=cc.getUsers(dbPath,testUserEquals = 0).sample(2)\n",
    "u=users.userID.values\n",
    "\n",
    "# Get data\n",
    "_,_,xTest, yTest = cc.getHiddenPeriodsData(dbPath,tblName,fieldList,oneHot=(n_classes >1),periodGranularity=periodGranularity,userIDs=u)\n",
    "if xTest is not None: TestHiddenPeriods()\n",
    "TestHiddenPeriods()\n",
    "\n",
    "print(' #### Test data test ###')\n",
    "numOfPeriods = 20\n",
    "# Hidden data test\n",
    "users=cc.getUsers(dbPath,testUserEquals = 1).sample(2)\n",
    "u=users.userID.values\n",
    "_,_,xTest, yTest = cc.getHiddenPeriodsData(dbPath,tblName,fieldList,oneHot=(n_classes >1),periodGranularity=periodGranularity,userIDs=u)\n",
    "TestHiddenPeriods(hiddenTestPeriods=numOfPeriods)\n",
    "#xTest2, yTest2_onehot, testDf2 = cc.getHiddenUsersData(dbPath,tblName,fieldList,oneHot= (n_classes >1),firstNPerc=0.5,periodGranularity=periodGranularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">Appendices</h3>"
   ]
=======
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data(seq_len, normalise_window):\n",
    "    f = open(\"3_Data/sinwave.csv\", 'rb').read()\n",
    "    data = f.decode().split('\\n')\n",
    "\n",
    "    sequence_length = seq_len + 1\n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "\n",
    "    result = np.array(result)\n",
    "\n",
    "    row = round(0.9 * result.shape[0])\n",
    "    train = result[:int(row), :]\n",
    "    np.random.shuffle(train)\n",
    "    x_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    x_test = result[int(row):, :-1]\n",
    "    y_test = result[int(row):, -1]\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))  \n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]\n",
    "\n",
    "seq_len = 1\n",
    "xdTrain, ydTrain, Xd_test, yd_test = load_data(seq_len, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dummy test\n",
    "n_steps = 1 # timesteps\n",
    "n_hidden = 160 # hidden layer num of features\n",
    "n_classes = 1\n",
    "batch_size = 20 #1344\n",
    "training_iterations=100\n",
    "learning_rate = 0.001\n",
    "cellType = \"BasicLSTMCell\"  # Choose: TimeFreqLSTMCell BasicLSTMCell\n",
    "\n",
    "#fieldList=\"UserID, t, HrsFrom5pm, isSun,isMon,isTue,isWed,isThu,isFri,isSat, t1,t2,t3,t4,t5,t10,t12hrs,t23_5hrs,t24hrs,t24_5hrs,t1wk,t2wks,t3wks,t4wks\"\n",
    "fieldList=\"UserID, t, HrsFrom5pm, isSun,isMon,isTue,isWed,isThu,isFri,isSat, t10,t12hrs,t24hrs,t1wk,t2wks,t3wks,t4wks\"\n",
    "n_input = 1\n",
    "\n",
    "# Build graph\n",
    "buildGraph(n_steps,n_input = n_input)\n",
    "# Initializing the variables\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "trainModel(xdTrain,ydTrain,sess,training_iterations)\n",
    "\n",
    "xdDummy = xdTrain.reshape(-1,1)\n",
    "predictions = getTestPredictions(xdTrain,ydTrain)\n",
    "print(metrics.classification_report(ydTrain[:,1],predictions))  # Need to feed it yTest not yTest_OneHot here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
>>>>>>> cb86cb51b5a122916cda72e92bab4a888cca7520
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
