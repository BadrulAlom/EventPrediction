{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\" style=\"background-color:#616161;color:white\">RNN Model</h1>\n",
    "\n",
    "Adapted from: https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">0. Setup</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Input Parameters</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Root path\n",
    "#root = \"C:/DS/Github/MusicRecommendation\"  # BA, Windows\n",
    "root = \"/home/badrul/git/EventPrediction\" # BA, Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Common Libraries</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "# Core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.debugger import Tracer    # Used for debugging\n",
    "import logging\n",
    "from random import *\n",
    "\n",
    "# File and database management\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "# Date/Time\n",
    "import datetime\n",
    "import time\n",
    "#from datetime import timedelta # Deprecated\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt             # Quick\n",
    "%matplotlib inline\n",
    "\n",
    "# Misc\n",
    "import random\n",
    "import importlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.basicConfig(filename='RNN.log',level=logging.DEBUG)\n",
    "\n",
    "#-------------- Custom Libs -----------------#\n",
    "os.chdir(root)\n",
    "\n",
    "# Import the codebase module\n",
    "fPath = root + \"/1_codemodule\"\n",
    "if fPath not in sys.path: sys.path.append(fPath)\n",
    "\n",
    "# Custom Libs\n",
    "import coreCode as cc\n",
    "import lastfmCode as fm\n",
    "print ('Ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Page Specific Libraries</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "# Data science (comment out if not needed)\n",
    "#from sklearn.manifold import TSNE\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "print ('Ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Load settings</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "settingsDict =  cc.loadSettings()\n",
    "dbPath = root + settingsDict['mainDbPath_sml']\n",
    "fmSimilarDbPath = root + settingsDict['fmSimilarDbPath']\n",
    "fmTagsDbPath = root + settingsDict['fmTagsDbPath']\n",
    "trackMetaDbPath = root + settingsDict['trackmetadata']\n",
    "periodGranularity = int(settingsDict['periodGranularity'])\n",
    "print ('Ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">1. Build Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases,n_steps):\n",
    "    # Current data input shape: (batchRows, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batchRows, n_input)\n",
    "    \n",
    "    # Unstack to get a list of 'n_steps' tensors of shape (batchRows, n_input)\n",
    "    x = tf.unstack(x, n_steps, 1)  # See https://stackoverflow.com/questions/45278276/tensorflow-lstm-dropout-implementation-shape-problems/45279243#45279243\n",
    "    \n",
    "    # Define a lstm cell with tensorflow\n",
    "    if cellType == \"LSTMCell\":\n",
    "        stacked_rnn=[]\n",
    "        for i in range(n_layers):\n",
    "            stacked_rnn.append(tf.nn.rnn_cell.LSTMCell(num_units=n_hidden, forget_bias=1., state_is_tuple=True))\n",
    "        multiRNNCell = tf.nn.rnn_cell.MultiRNNCell(cells=stacked_rnn, state_is_tuple=True)\n",
    "        outputs, states = rnn.static_rnn(multiRNNCell, x, dtype=tf.float32)\n",
    "        \n",
    "                \n",
    "        #lstm_cell = rnn.BasicLSTMCell(num_units=n_hidden, forget_bias=1.0)\n",
    "        #outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    \n",
    "    elif cellType == \"TimeFreqLSTMCell\":\n",
    "        lstm_cell =rnn.TimeFreqLSTMCell(n_hidden, use_peepholes=True, feature_size= 22, forget_bias=1.0)\n",
    "        outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    elif cellType == \"GridLSTMCell\":\n",
    "        lstm_cell =rnn.GridLSTMCell(n_hidden, forget_bias=1.0)\n",
    "        outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)        \n",
    "    else:\n",
    "        print(\"Did not recognize {}\".format(cellType))\n",
    "    # Get lstm cell output\n",
    "    \n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "def _buildGraph(n_steps,n_input, n_weighting):\n",
    "    global x, y, _pred, _predProb, _logits, _cost, optimizer, _accuracy,_correct_pred\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    # tf Graph input\n",
    "    x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "    y = tf.placeholder(\"int64\", [None])\n",
    "    \n",
    "    # Define weights\n",
    "    weights = {'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))}\n",
    "    biases = {'out': tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "    # Evaluate model\n",
    "    _logits = RNN(x, weights, biases,n_steps)\n",
    "    lossW = tf.add(1,tf.multiply(tf.cast(tf.equal(y,1),'int32'),n_weighting))\n",
    "    _cost = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(logits=_logits, labels=y,weights=lossW))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(_cost)\n",
    "    \n",
    "    _predProb =tf.nn.softmax(_logits)  # Convert to proper probs\n",
    "    _pred =tf.argmax(_predProb,1)  # Take the highest prob\n",
    "    _correct_pred = tf.equal(_pred, y)\n",
    "    _accuracy = tf.reduce_mean(tf.cast(_correct_pred, tf.float32))\n",
    "print('Ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ResetModel():\n",
    "    try:\n",
    "        sess.close()\n",
    "        tf.reset_default_graph()\n",
    "    except NameError:\n",
    "        return\n",
    "    \n",
    "def initializeModel(n_steps,n_input,n_weighting,loadFromSave):\n",
    "    global sess\n",
    "\n",
    "    # Build graph\n",
    "    _buildGraph(n_steps,n_input,n_weighting)\n",
    "\n",
    "    # Initializing the variables\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    sess = tf.Session() # Has tome come after init\n",
    "    if loadFromSave:\n",
    "        saver.restore(sess,'./3_Data/saves/model.ckpt')\n",
    "    else:\n",
    "        sess.run(init)\n",
    "    print('Model initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">2. Model Training Functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "def randomSelectFromData(_X, _Y,_batchRows = 10, numOfSamples =1):\n",
    "    \n",
    "    # Num of periods = batch size\n",
    "    \n",
    "    # Training cycle\n",
    "    \n",
    "    XCols=np.shape(_X)[1]\n",
    "    YCols=np.shape(_Y)[1]\n",
    "    depth = n_steps\n",
    "    \n",
    "    totalRows=np.shape(_X)[0]\n",
    "    # Select random periods (ones where we will always get enough history to go with it)\n",
    "    periodsList = random.sample(range(batchRows+depth, totalRows), _batchRows)\n",
    "    \n",
    "    # Debugging...\n",
    "    #for i in range(_batchRows -1):\n",
    "    #    periodsList[i+1]=periodsList[i]-1\n",
    "    \n",
    "    # Pre-Initialize batch arrays\n",
    "    batch_x=np.zeros([_batchRows,depth,XCols])\n",
    "    batch_y=np.zeros([_batchRows])\n",
    "\n",
    "    batch_row =0\n",
    "    \n",
    "    for periodPos in periodsList:            \n",
    "        # Log every so often \n",
    "        if (periodPos % 1) == 0: \n",
    "            timeNow =str(datetime.datetime.now())\n",
    "            #print(\"{} Now adding random period {} into batch_row {}. ({}%)\".format(timeNow,idx1,batch_row, round((batch_row/_batchRows)*100,2)))\n",
    "            #logging.info(\"{} Now adding random period {} into batch_row ({}%)\".format(timeNow, idx1,batch_row, round((batch_row/_batchRows)*100,2)))\n",
    "\n",
    "        batch_x[batch_row] = _X[periodPos-depth:periodPos].reshape(1,depth,XCols)\n",
    "        batch_y[batch_row] = _Y[periodPos]\n",
    "        batch_row +=1\n",
    "        \n",
    "    return batch_x, batch_y\n",
    "print ('Ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "###           MODEL 1    Train             ###\n",
    "##############################################\n",
    "def trainModel_1(batch_x, batch_y):        \n",
    "    sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "    # Calculate loss & accuracy\n",
    "    loss = sess.run(_cost,feed_dict={x: batch_x, y: batch_y})\n",
    "    acc = sess.run(_accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "    \n",
    "    return loss, acc\n",
    "print('Ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">3. Model Testing Functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Launch the graph\n",
    "def TestPredictions1(_X, _Y, sess, _batchRows = 10, testPeriods = None):\n",
    "    # Training cycle\n",
    "    totalRows=np.shape(_X)[0]\n",
    "    XCols=np.shape(_X)[1]\n",
    "    YCols=_Y\n",
    "    depth = n_steps\n",
    "    \n",
    "    # If no test periods were provided generate your own\n",
    "    if testPeriods is None:\n",
    "        # Select periods where we will always get enough history to go with it\n",
    "        \n",
    "        testPeriods = random.sample(range(batchRows+depth, totalRows), _batchRows)\n",
    "    else:\n",
    "        testPeriods = testPeriods + batchRows+depth-1\n",
    "        _batchRows = len(testPeriods)\n",
    "     \n",
    "    # Pre-Initialize batch arrays\n",
    "    batch_x=np.zeros([_batchRows,depth,XCols])\n",
    "    batch_y=np.zeros([_batchRows])\n",
    "\n",
    "    batch_row =0\n",
    "    for idx1 in testPeriods:            \n",
    "        if (idx1 % 1) == 0: \n",
    "            timeNow =str(datetime.datetime.now())\n",
    "            #print(\"{} Now testing on period {} ({}%)\".format(timeNow,idx1,round((batch_row/_batchRows)*100,2)))\n",
    "            logging.info(\"{} Now testing period {} ({}%)\".format(timeNow, idx1,round((batch_row/_batchRows)*100,2)))\n",
    "\n",
    "        batch_x[batch_row] = _X[idx1-depth:idx1].reshape(1,depth,XCols)\n",
    "        batch_y[batch_row] = _Y[idx1]\n",
    "        batch_row +=1\n",
    "    \n",
    "    print (\"Processed {}\".format(_batchRows))\n",
    "    # Predict for this period\n",
    "    prob = sess.run(_predProb, feed_dict={x: batch_x, y: batch_y})\n",
    "    predictions = sess.run(_pred, feed_dict={x: batch_x, y: batch_y})\n",
    "    \n",
    "    return predictions, batch_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Test hidden periods</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TestHiddenPeriods(hiddenTestPeriods=50, useTestData = False):\n",
    "\n",
    "    print('{} Hidden Periods\\n'.format(hiddenTestPeriods))\n",
    "    print (\"Cell type= {}, learning_rate = {}, Iterations = {}, batch size = {}, Steps = {}, Hidden Layers = {}, Classes = {}\\n\".format(cellType,learning_rate,samplesPerUser,batch_size, n_steps ,n_hidden,n_classes))\n",
    "\n",
    "    if useTestData == False:\n",
    "        predictions,labels = TestPredictions1(xTrain,yTrain,sess,numOfPeriods=hiddenTestPeriods)\n",
    "    else:\n",
    "        predictions,labels = TestPredictions1(xTest,yTest,sess,numOfPeriods=hiddenTestPeriods)\n",
    "    \n",
    "    print(np.shape(labels),np.shape(predictions))    \n",
    "    print(metrics.classification_report(labels,predictions))  # Need to feed it yTest not yTest_OneHot here\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "def TrainModel(printOnBatchIteration=True,printOnSampleIteration=1,enableLogging=False, _saveModel=False):\n",
    "    \n",
    "    counter =0 # Used to keep track of every iteration. (Does not loop back to 0).\n",
    "    batch_y=[]\n",
    "    batch_x=[]\n",
    "    \n",
    "    loss=np.zeros([user_iteration*samplesPerUser*batch_Iterations])\n",
    "    acc=np.zeros([user_iteration*samplesPerUser*batch_Iterations])\n",
    "    \n",
    "    \n",
    "    trainUsers=(cc.getUsers(dbPath,testUserFlag=0))  # Get list of users\n",
    "    np.random.shuffle(trainUsers)\n",
    "\n",
    "    for userCount in range(user_iteration):  # Iterate through user selection\n",
    "        # Get user data\n",
    "        userID = int(trainUsers[userCount]) # Randomly select 1 user\n",
    "        xTrain, yTrain, xTest, yTest = cc.SelectUserData_TrainTest(dbPath,tblName,fieldList,userIDs=[userID],oneHot=False,periodGranularity=periodGranularity)\n",
    "\n",
    "        if xTrain is not None: # Make sure we have data\n",
    "            # Print message\n",
    "            timeNow =datetime.datetime.now().strftime('%D %H:%M:%S')\n",
    "            print('{} User {} UserID {} (Total plays {})'.format(timeNow, userCount,userID,sum(yTrain)))\n",
    "            if enableLogging: logging.info('{} Now processing random user {}'.format(timeNow, userID))\n",
    "\n",
    "            for i in range(samplesPerUser):  # Num of mini-batches\n",
    "                \n",
    "                # Randomly select from the train data\n",
    "                batch_x, batch_y = randomSelectFromData(xTrain, yTrain, _batchRows=batchRows)\n",
    "                \n",
    "                for j in range(batch_Iterations): # Num of times to iterate over the batch\n",
    "                    loss[counter],acc[counter] = trainModel_1(batch_x,batch_y)\n",
    "                    \n",
    "                    if printOnBatchIteration:\n",
    "                        timeNow =datetime.datetime.now().strftime('%D %H:%M:%S')\n",
    "                        print(\"  User {} Mini-batch {} Iteration {} Loss={:.6f}, Training Accuracy={:.5f}\".format(userCount,i, j, loss[counter], acc[counter]))\n",
    "                        if enableLogging: logging.info(s)\n",
    "                    counter+=1\n",
    "\n",
    "                \n",
    "                if i % printOnSampleIteration == 0 or i==samplesPerUser:\n",
    "                    # Sample results\n",
    "                    predictions = sess.run(_pred, feed_dict={x: batch_x, y: batch_y})\n",
    "                    logits= sess.run(_logits, feed_dict={x: batch_x, y: batch_y})\n",
    "                    prob= sess.run(_predProb, feed_dict={x: batch_x, y: batch_y})                    \n",
    "                    \n",
    "                    prec,rec, _, _ = metrics.precision_recall_fscore_support(batch_y,predictions, average='binary')\n",
    "                    timeNow =datetime.datetime.now().strftime('%D %H:%M:%S')\n",
    "                    s='{} Sample {} of {} Precision {} Recall {}\\n'.format(timeNow, i, samplesPerUser,np.round(prec,3),np.round(rec,3))\n",
    "                    print(s)\n",
    "                    if enableLogging: logging.info(s)\n",
    "                    \n",
    "            # End of user training - Perform test\n",
    "            xTest, yTest = randomSelectFromData(xTest, yTest, _batchRows=batchRows, numOfSamples=2)\n",
    "            predictions = sess.run(_pred, feed_dict={x: xTest, y: yTest})\n",
    "            logits= sess.run(_logits, feed_dict={x: xTest, y: yTest})\n",
    "            prob= sess.run(_predProb, feed_dict={x: xTest, y: yTest})                    \n",
    "\n",
    "            prec,rec, _, _ = metrics.precision_recall_fscore_support(yTest,predictions, average='binary')\n",
    "            \n",
    "            timeNow =datetime.datetime.now().strftime('%D %H:%M:%S')\n",
    "            s='{} UserID {} Test: Precision {} Recall {}\\n'.format(timeNow, userID,np.round(prec,3),np.round(rec,3))\n",
    "            print(s)\n",
    "            if enableLogging: logging.info(s)\n",
    "            print(metrics.classification_report(yTest,predictions))  # Need to feed it yTest not yTest_OneHot here\n",
    "            \n",
    "            if _saveModel:\n",
    "                saver = tf.train.Saver()\n",
    "                saver.save(sess,\"./3_Data/saves/model.ckpt\")\n",
    "\n",
    "print('Training completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Code needs tidying up\n",
    "\n",
    "def TestModel():\n",
    "    print('Testing held out users')\n",
    "    userLabels=[]\n",
    "    userPred=[]\n",
    "    totalLabels = []\n",
    "    totalPred = []\n",
    "    avLoss =0\n",
    "    avAcc =0\n",
    "    \n",
    "    \n",
    "    users=cc.getUsers(dbPath,testUserFlag = 1)  # Get all test users\n",
    "\n",
    "    prec= np.zeros(len(users))\n",
    "    rec = np.zeros(len(users))\n",
    "    \n",
    "    usrCount = 0\n",
    "    for usr in users: # For each test user    \n",
    "        # Select all data for each user\n",
    "        xTest, yTest = cc.SelectTestUserData(dbPath,tblName,fieldList,userIDs=usr,oneHot=False,periodGranularity=periodGranularity)\n",
    "        \n",
    "        if xTest is not None:\n",
    "            for i in range(10):  # Select 10 random batches\n",
    "                batch_x, batch_y = randomSelectFromData(xTest, yTest, _batchRows=batchRows)\n",
    "\n",
    "                p = sess.run(_pred, feed_dict={x: batch_x, y: batch_y})\n",
    "                \n",
    "                loss = sess.run(_cost,feed_dict={x: batch_x, y: batch_y})\n",
    "                acc = sess.run(_accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "                avLoss+=loss\n",
    "                avAcc+=acc\n",
    "\n",
    "                if userLabels == []:\n",
    "                    userLabels= batch_y\n",
    "                    userPred = p\n",
    "                else:\n",
    "                    userLabels = np.append(userLabels,batch_y)\n",
    "                    userPred = np.append(userPred,p)\n",
    "        \n",
    "        prec[usrCount],rec[usrCount], _, _ = metrics.precision_recall_fscore_support(userLabels,userPred, average='binary')\n",
    "        print('User {} of {} Av loss {} Av acc {}'.format(usrCount , len(users), np.round(avLoss/10,3), np.round(avAcc/10,3)))\n",
    "        print('User {} of {} Precision {} Recall {}'.format(usrCount , len(users), np.round(prec[usrCount],3),np.round(rec[usrCount],3)))\n",
    "        avLoss=0\n",
    "        avAcc = 0\n",
    "        if totalLabels ==[]:\n",
    "            totalLabels = userLabels\n",
    "            totalPred = userPred\n",
    "        else:\n",
    "            totalLabels = np.append(totalLabels,userLabels)\n",
    "            totalPred = np.append(totalPred,userPred)\n",
    "        usrCount+=1                \n",
    "\n",
    "    print('Overall results:')\n",
    "    print(metrics.classification_report(totalLabels,totalPred))  # Need to feed it yTest not yTest_OneHot here\n",
    "    pMn=round(prec.mean(),3)\n",
    "    pSd=round(prec.std(),3)\n",
    "    rMn=round(rec.mean(),3)\n",
    "    rSd=round(rec.std(),3)\n",
    "    print (\"Av. precision {} +/- {}, Av. recall {}+/{},\".format(pMn,pSd,rMn,rSd))\n",
    "    \n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess,\"./3_Data/saves/model.ckpt\")\n",
    "    print('Testing complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SelectTestUsers(newUsers=10):\n",
    "    newUsers = 10   # Num of randomly selected users to separate out\n",
    "    con = sqlite3.connect(dbPath)\n",
    "\n",
    "    # First reset back to 0\n",
    "    con.execute(\"Update tblUsers Set TestUser = 0\")\n",
    "    con.commit()\n",
    "\n",
    "    # Select random users\n",
    "    sqlStr= \"SELECT UserID FROM tblUsers Group by UserID ORDER BY RANDOM() LIMIT {}\".format(newUsers)\n",
    "\n",
    "    newUsersList = pd.read_sql_query(sqlStr, con)\n",
    "    for row in newUsersList.itertuples():\n",
    "        sqlStr = \"Update tblUsers Set TestUser = 1 where UserID = {}\".format(row[1])\n",
    "        con.execute(sqlStr)\n",
    "    con.commit()\n",
    "    con.close()\n",
    "\n",
    "    np.array(newUsersList).reshape(1,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:green;color:white\">4. ...And action!</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized\n",
      "Skipping user 8 as not enough periods (4862)\n",
      "08/22/17 20:15:49 User 1 UserID 16 (Total plays [3886])\n",
      "08/22/17 20:19:09 Sample 0 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/22/17 20:24:16 Sample 1 of 50 Precision 1.0 Recall 0.667\n",
      "\n",
      "08/22/17 20:27:30 Sample 2 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/22/17 20:30:37 Sample 3 of 50 Precision 0.5 Recall 0.5\n",
      "\n",
      "08/22/17 20:35:52 Sample 4 of 50 Precision 0.333 Recall 0.667\n",
      "\n",
      "08/22/17 20:39:07 Sample 5 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/22/17 20:42:24 Sample 6 of 50 Precision 1.0 Recall 0.5\n",
      "\n",
      "08/22/17 20:45:38 Sample 7 of 50 Precision 0.5 Recall 0.667\n",
      "\n",
      "08/22/17 20:48:49 Sample 8 of 50 Precision 0.667 Recall 1.0\n",
      "\n",
      "08/22/17 20:52:07 Sample 9 of 50 Precision 0.5 Recall 0.5\n",
      "\n",
      "08/22/17 20:55:21 Sample 10 of 50 Precision 0.857 Recall 0.857\n",
      "\n",
      "08/22/17 20:58:34 Sample 11 of 50 Precision 0.667 Recall 1.0\n",
      "\n",
      "08/22/17 21:01:47 Sample 12 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/22/17 21:05:02 Sample 13 of 50 Precision 0.5 Recall 0.667\n",
      "\n",
      "08/22/17 21:08:19 Sample 14 of 50 Precision 0.4 Recall 0.667\n",
      "\n",
      "08/22/17 21:11:26 Sample 15 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/22/17 21:16:21 Sample 16 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/22/17 21:19:55 Sample 17 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/22/17 21:23:06 Sample 18 of 50 Precision 1.0 Recall 0.333\n",
      "\n",
      "08/22/17 21:26:19 Sample 19 of 50 Precision 1.0 Recall 0.5\n",
      "\n",
      "08/22/17 21:29:35 Sample 20 of 50 Precision 1.0 Recall 0.667\n",
      "\n",
      "08/22/17 21:32:51 Sample 21 of 50 Precision 1.0 Recall 0.25\n",
      "\n",
      "08/22/17 21:36:02 Sample 22 of 50 Precision 1.0 Recall 0.5\n",
      "\n",
      "08/22/17 21:39:11 Sample 23 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/22/17 21:42:26 Sample 24 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/22/17 21:45:36 Sample 25 of 50 Precision 0.5 Recall 0.333\n",
      "\n",
      "08/22/17 21:48:47 Sample 26 of 50 Precision 0.75 Recall 1.0\n",
      "\n",
      "08/22/17 21:52:03 Sample 27 of 50 Precision 0.5 Recall 0.429\n",
      "\n",
      "08/22/17 21:55:17 Sample 28 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/22/17 21:58:26 Sample 29 of 50 Precision 1.0 Recall 0.5\n",
      "\n",
      "08/22/17 22:01:38 Sample 30 of 50 Precision 1.0 Recall 0.75\n",
      "\n",
      "08/22/17 22:04:48 Sample 31 of 50 Precision 0.5 Recall 0.5\n",
      "\n",
      "08/22/17 22:07:57 Sample 32 of 50 Precision 0.5 Recall 0.5\n",
      "\n",
      "08/22/17 22:11:14 Sample 33 of 50 Precision 0.333 Recall 0.333\n",
      "\n",
      "08/22/17 22:14:30 Sample 34 of 50 Precision 0.333 Recall 0.333\n",
      "\n",
      "08/22/17 22:17:48 Sample 35 of 50 Precision 1.0 Recall 0.5\n",
      "\n",
      "08/22/17 22:21:06 Sample 36 of 50 Precision 0.6 Recall 0.75\n",
      "\n",
      "08/22/17 22:24:18 Sample 37 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/22/17 22:27:32 Sample 38 of 50 Precision 0.714 Recall 0.833\n",
      "\n",
      "08/22/17 22:30:48 Sample 39 of 50 Precision 0.667 Recall 1.0\n",
      "\n",
      "08/22/17 22:34:01 Sample 40 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/22/17 22:37:10 Sample 41 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/22/17 22:40:27 Sample 42 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/22/17 22:43:43 Sample 43 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/22/17 22:46:57 Sample 44 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/22/17 22:50:11 Sample 45 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/22/17 22:53:20 Sample 46 of 50 Precision 0.667 Recall 0.667\n",
      "\n",
      "08/22/17 22:56:30 Sample 47 of 50 Precision 0.8 Recall 1.0\n",
      "\n",
      "08/22/17 22:59:43 Sample 48 of 50 Precision 0.5 Recall 1.0\n",
      "\n",
      "08/22/17 23:02:56 Sample 49 of 50 Precision 1.0 Recall 0.5\n",
      "\n",
      "08/22/17 23:03:06 UserID 16 Test: Precision 0.0 Recall 0.0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00        50\n",
      "\n",
      "avg / total       1.00      1.00      1.00        50\n",
      "\n",
      "08/22/17 23:03:07 User 2 UserID 91 (Total plays [3303])\n",
      "08/22/17 23:06:18 Sample 0 of 50 Precision 0.8 Recall 1.0\n",
      "\n",
      "08/22/17 23:09:25 Sample 1 of 50 Precision 0.667 Recall 0.667\n",
      "\n",
      "08/22/17 23:12:35 Sample 2 of 50 Precision 0.571 Recall 0.8\n",
      "\n",
      "08/22/17 23:15:50 Sample 3 of 50 Precision 0.667 Recall 0.571\n",
      "\n",
      "08/22/17 23:19:02 Sample 4 of 50 Precision 0.6 Recall 0.6\n",
      "\n",
      "08/22/17 23:22:16 Sample 5 of 50 Precision 0.5 Recall 0.25\n",
      "\n",
      "08/22/17 23:25:29 Sample 6 of 50 Precision 0.75 Recall 1.0\n",
      "\n",
      "08/22/17 23:28:38 Sample 7 of 50 Precision 1.0 Recall 0.8\n",
      "\n",
      "08/22/17 23:31:54 Sample 8 of 50 Precision 0.75 Recall 1.0\n",
      "\n",
      "08/22/17 23:35:09 Sample 9 of 50 Precision 0.778 Recall 0.875\n",
      "\n",
      "08/22/17 23:38:27 Sample 10 of 50 Precision 0.889 Recall 1.0\n",
      "\n",
      "08/22/17 23:41:44 Sample 11 of 50 Precision 0.833 Recall 0.833\n",
      "\n",
      "08/22/17 23:44:59 Sample 12 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/22/17 23:48:13 Sample 13 of 50 Precision 0.875 Recall 1.0\n",
      "\n",
      "08/22/17 23:51:24 Sample 14 of 50 Precision 1.0 Recall 0.75\n",
      "\n",
      "08/22/17 23:54:32 Sample 15 of 50 Precision 0.625 Recall 0.833\n",
      "\n",
      "08/22/17 23:57:49 Sample 16 of 50 Precision 0.667 Recall 0.667\n",
      "\n",
      "08/23/17 00:01:06 Sample 17 of 50 Precision 0.5 Recall 0.333\n",
      "\n",
      "08/23/17 00:04:18 Sample 18 of 50 Precision 0.5 Recall 0.5\n",
      "\n",
      "08/23/17 00:07:34 Sample 19 of 50 Precision 0.5 Recall 1.0\n",
      "\n",
      "08/23/17 00:10:52 Sample 20 of 50 Precision 1.0 Recall 0.833\n",
      "\n",
      "08/23/17 00:14:01 Sample 21 of 50 Precision 0.5 Recall 0.6\n",
      "\n",
      "08/23/17 00:17:18 Sample 22 of 50 Precision 0.75 Recall 0.75\n",
      "\n",
      "08/23/17 00:20:27 Sample 23 of 50 Precision 0.5 Recall 0.6\n",
      "\n",
      "08/23/17 00:23:36 Sample 24 of 50 Precision 1.0 Recall 0.8\n",
      "\n",
      "08/23/17 00:26:47 Sample 25 of 50 Precision 0.778 Recall 0.636\n",
      "\n",
      "08/23/17 00:29:56 Sample 26 of 50 Precision 1.0 Recall 0.5\n",
      "\n",
      "08/23/17 00:33:10 Sample 27 of 50 Precision 0.4 Recall 0.667\n",
      "\n",
      "08/23/17 00:36:27 Sample 28 of 50 Precision 0.875 Recall 1.0\n",
      "\n",
      "08/23/17 00:39:40 Sample 29 of 50 Precision 0.75 Recall 0.75\n",
      "\n",
      "08/23/17 00:42:50 Sample 30 of 50 Precision 0.429 Recall 0.6\n",
      "\n",
      "08/23/17 00:46:03 Sample 31 of 50 Precision 0.667 Recall 0.5\n",
      "\n",
      "08/23/17 00:49:15 Sample 32 of 50 Precision 1.0 Recall 0.75\n",
      "\n",
      "08/23/17 00:52:26 Sample 33 of 50 Precision 1.0 Recall 0.75\n",
      "\n",
      "08/23/17 00:55:36 Sample 34 of 50 Precision 1.0 Recall 0.5\n",
      "\n",
      "08/23/17 00:58:52 Sample 35 of 50 Precision 0.75 Recall 1.0\n",
      "\n",
      "08/23/17 01:02:07 Sample 36 of 50 Precision 0.833 Recall 0.833\n",
      "\n",
      "08/23/17 01:05:20 Sample 37 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/23/17 01:08:37 Sample 38 of 50 Precision 0.5 Recall 0.5\n",
      "\n",
      "08/23/17 01:11:53 Sample 39 of 50 Precision 0.833 Recall 0.833\n",
      "\n",
      "08/23/17 01:15:04 Sample 40 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/23/17 01:18:17 Sample 41 of 50 Precision 0.833 Recall 1.0\n",
      "\n",
      "08/23/17 01:21:31 Sample 42 of 50 Precision 0.75 Recall 0.5\n",
      "\n",
      "08/23/17 01:24:46 Sample 43 of 50 Precision 0.571 Recall 0.8\n",
      "\n",
      "08/23/17 01:28:02 Sample 44 of 50 Precision 0.5 Recall 0.75\n",
      "\n",
      "08/23/17 01:31:16 Sample 45 of 50 Precision 0.833 Recall 0.833\n",
      "\n",
      "08/23/17 01:34:32 Sample 46 of 50 Precision 0.8 Recall 1.0\n",
      "\n",
      "08/23/17 01:37:45 Sample 47 of 50 Precision 1.0 Recall 0.75\n",
      "\n",
      "08/23/17 01:40:57 Sample 48 of 50 Precision 0.857 Recall 1.0\n",
      "\n",
      "08/23/17 01:44:08 Sample 49 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/23/17 01:44:19 UserID 91 Test: Precision 0.6 Recall 1.0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.91      0.95        44\n",
      "        1.0       0.60      1.00      0.75         6\n",
      "\n",
      "avg / total       0.95      0.92      0.93        50\n",
      "\n",
      "08/23/17 01:44:19 User 3 UserID 31 (Total plays [4787])\n",
      "08/23/17 01:47:32 Sample 0 of 50 Precision 1.0 Recall 0.75\n",
      "\n",
      "08/23/17 01:50:48 Sample 1 of 50 Precision 1.0 Recall 0.714\n",
      "\n",
      "08/23/17 01:54:05 Sample 2 of 50 Precision 0.833 Recall 0.714\n",
      "\n",
      "08/23/17 01:57:18 Sample 3 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/23/17 02:00:32 Sample 4 of 50 Precision 0.667 Recall 0.8\n",
      "\n",
      "08/23/17 02:03:45 Sample 5 of 50 Precision 0.667 Recall 0.667\n",
      "\n",
      "08/23/17 02:06:58 Sample 6 of 50 Precision 1.0 Recall 0.333\n",
      "\n",
      "08/23/17 02:10:15 Sample 7 of 50 Precision 0.8 Recall 1.0\n",
      "\n",
      "08/23/17 02:13:24 Sample 8 of 50 Precision 0.625 Recall 0.833\n",
      "\n",
      "08/23/17 02:16:41 Sample 9 of 50 Precision 0.889 Recall 1.0\n",
      "\n",
      "08/23/17 02:19:56 Sample 10 of 50 Precision 0.8 Recall 0.8\n",
      "\n",
      "08/23/17 02:23:16 Sample 11 of 50 Precision 0.714 Recall 0.833\n",
      "\n",
      "08/23/17 02:26:26 Sample 12 of 50 Precision 0.8 Recall 0.8\n",
      "\n",
      "08/23/17 02:29:40 Sample 13 of 50 Precision 0.667 Recall 0.8\n",
      "\n",
      "08/23/17 02:32:54 Sample 14 of 50 Precision 0.727 Recall 1.0\n",
      "\n",
      "08/23/17 02:36:06 Sample 15 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/23/17 02:39:18 Sample 16 of 50 Precision 0.8 Recall 1.0\n",
      "\n",
      "08/23/17 02:42:34 Sample 17 of 50 Precision 0.909 Recall 0.769\n",
      "\n",
      "08/23/17 02:45:50 Sample 18 of 50 Precision 1.0 Recall 0.4\n",
      "\n",
      "08/23/17 02:49:13 Sample 19 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/23/17 02:53:09 Sample 20 of 50 Precision 0.8 Recall 0.889\n",
      "\n",
      "08/23/17 02:58:11 Sample 21 of 50 Precision 1.0 Recall 0.667\n",
      "\n",
      "08/23/17 03:01:30 Sample 22 of 50 Precision 0.833 Recall 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/23/17 03:04:48 Sample 23 of 50 Precision 1.0 Recall 0.889\n",
      "\n",
      "08/23/17 03:08:06 Sample 24 of 50 Precision 0.8 Recall 1.0\n",
      "\n",
      "08/23/17 03:11:22 Sample 25 of 50 Precision 0.8 Recall 0.8\n",
      "\n",
      "08/23/17 03:14:45 Sample 26 of 50 Precision 0.8 Recall 1.0\n",
      "\n",
      "08/23/17 03:18:10 Sample 27 of 50 Precision 1.0 Recall 0.5\n",
      "\n",
      "08/23/17 03:21:28 Sample 28 of 50 Precision 0.455 Recall 0.833\n",
      "\n",
      "08/23/17 03:24:45 Sample 29 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/23/17 03:27:57 Sample 30 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 03:31:14 Sample 31 of 50 Precision 0.667 Recall 0.667\n",
      "\n",
      "08/23/17 03:34:32 Sample 32 of 50 Precision 0.875 Recall 0.875\n",
      "\n",
      "08/23/17 03:37:48 Sample 33 of 50 Precision 0.714 Recall 0.833\n",
      "\n",
      "08/23/17 03:41:06 Sample 34 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/23/17 03:44:25 Sample 35 of 50 Precision 1.0 Recall 0.667\n",
      "\n",
      "08/23/17 03:47:39 Sample 36 of 50 Precision 0.5 Recall 0.5\n",
      "\n",
      "08/23/17 03:50:54 Sample 37 of 50 Precision 0.75 Recall 0.6\n",
      "\n",
      "08/23/17 03:54:14 Sample 38 of 50 Precision 0.889 Recall 1.0\n",
      "\n",
      "08/23/17 03:57:30 Sample 39 of 50 Precision 0.75 Recall 0.75\n",
      "\n",
      "08/23/17 04:00:44 Sample 40 of 50 Precision 0.889 Recall 1.0\n",
      "\n",
      "08/23/17 04:03:57 Sample 41 of 50 Precision 0.5 Recall 1.0\n",
      "\n",
      "08/23/17 04:07:40 Sample 42 of 50 Precision 0.667 Recall 1.0\n",
      "\n",
      "08/23/17 04:10:44 Sample 43 of 50 Precision 0.667 Recall 0.8\n",
      "\n",
      "08/23/17 04:14:45 Sample 44 of 50 Precision 0.7 Recall 0.778\n",
      "\n",
      "08/23/17 04:19:13 Sample 45 of 50 Precision 1.0 Recall 0.75\n",
      "\n",
      "08/23/17 04:22:25 Sample 46 of 50 Precision 1.0 Recall 0.667\n",
      "\n",
      "08/23/17 04:25:43 Sample 47 of 50 Precision 0.667 Recall 0.5\n",
      "\n",
      "08/23/17 04:29:03 Sample 48 of 50 Precision 1.0 Recall 0.778\n",
      "\n",
      "08/23/17 04:32:20 Sample 49 of 50 Precision 0.556 Recall 0.833\n",
      "\n",
      "08/23/17 04:32:30 UserID 31 Test: Precision 1.0 Recall 1.0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00        48\n",
      "        1.0       1.00      1.00      1.00         2\n",
      "\n",
      "avg / total       1.00      1.00      1.00        50\n",
      "\n",
      "08/23/17 04:32:30 User 4 UserID 55 (Total plays [2499])\n",
      "08/23/17 04:35:44 Sample 0 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 04:38:56 Sample 1 of 50 Precision 0.375 Recall 1.0\n",
      "\n",
      "08/23/17 04:42:13 Sample 2 of 50 Precision 0.333 Recall 0.5\n",
      "\n",
      "08/23/17 04:45:26 Sample 3 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/23/17 04:48:38 Sample 4 of 50 Precision 0.4 Recall 0.667\n",
      "\n",
      "08/23/17 04:51:53 Sample 5 of 50 Precision 1.0 Recall 0.5\n",
      "\n",
      "08/23/17 04:55:12 Sample 6 of 50 Precision 0.5 Recall 0.5\n",
      "\n",
      "08/23/17 04:58:24 Sample 7 of 50 Precision 0.667 Recall 1.0\n",
      "\n",
      "08/23/17 05:01:32 Sample 8 of 50 Precision 0.5 Recall 0.5\n",
      "\n",
      "08/23/17 05:04:40 Sample 9 of 50 Precision 1.0 Recall 0.5\n",
      "\n",
      "08/23/17 05:07:51 Sample 10 of 50 Precision 1.0 Recall 0.667\n",
      "\n",
      "08/23/17 05:11:01 Sample 11 of 50 Precision 0.5 Recall 1.0\n",
      "\n",
      "08/23/17 05:14:15 Sample 12 of 50 Precision 0.75 Recall 0.857\n",
      "\n",
      "08/23/17 05:17:27 Sample 13 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/23/17 05:20:40 Sample 14 of 50 Precision 0.667 Recall 1.0\n",
      "\n",
      "08/23/17 05:23:51 Sample 15 of 50 Precision 0.857 Recall 0.857\n",
      "\n",
      "08/23/17 05:27:09 Sample 16 of 50 Precision 0.8 Recall 1.0\n",
      "\n",
      "08/23/17 05:30:28 Sample 17 of 50 Precision 0.8 Recall 1.0\n",
      "\n",
      "08/23/17 05:33:45 Sample 18 of 50 Precision 0.667 Recall 1.0\n",
      "\n",
      "08/23/17 05:36:59 Sample 19 of 50 Precision 0.5 Recall 0.714\n",
      "\n",
      "08/23/17 05:40:10 Sample 20 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/23/17 05:43:23 Sample 21 of 50 Precision 0.2 Recall 0.5\n",
      "\n",
      "08/23/17 05:46:31 Sample 22 of 50 Precision 0.625 Recall 0.833\n",
      "\n",
      "08/23/17 05:49:42 Sample 23 of 50 Precision 0.8 Recall 1.0\n",
      "\n",
      "08/23/17 05:53:02 Sample 24 of 50 Precision 0.4 Recall 1.0\n",
      "\n",
      "08/23/17 05:56:18 Sample 25 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 05:59:33 Sample 26 of 50 Precision 0.667 Recall 1.0\n",
      "\n",
      "08/23/17 06:02:47 Sample 27 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/23/17 06:06:03 Sample 28 of 50 Precision 0.5 Recall 1.0\n",
      "\n",
      "08/23/17 06:09:14 Sample 29 of 50 Precision 0.5 Recall 0.5\n",
      "\n",
      "08/23/17 06:12:25 Sample 30 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 06:15:37 Sample 31 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 06:18:53 Sample 32 of 50 Precision 0.4 Recall 0.667\n",
      "\n",
      "08/23/17 06:22:03 Sample 33 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 06:25:27 Sample 34 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/23/17 06:28:45 Sample 35 of 50 Precision 1.0 Recall 0.667\n",
      "\n",
      "08/23/17 06:31:55 Sample 36 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 06:35:08 Sample 37 of 50 Precision 0.6 Recall 0.75\n",
      "\n",
      "08/23/17 06:38:22 Sample 38 of 50 Precision 0.5 Recall 0.333\n",
      "\n",
      "08/23/17 06:41:35 Sample 39 of 50 Precision 0.5 Recall 0.5\n",
      "\n",
      "08/23/17 06:44:44 Sample 40 of 50 Precision 0.333 Recall 0.667\n",
      "\n",
      "08/23/17 06:47:55 Sample 41 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/23/17 06:51:11 Sample 42 of 50 Precision 0.6 Recall 0.6\n",
      "\n",
      "08/23/17 06:54:21 Sample 43 of 50 Precision 0.571 Recall 1.0\n",
      "\n",
      "08/23/17 06:57:32 Sample 44 of 50 Precision 0.5 Recall 0.667\n",
      "\n",
      "08/23/17 07:01:11 Sample 45 of 50 Precision 0.5 Recall 1.0\n",
      "\n",
      "08/23/17 07:04:19 Sample 46 of 50 Precision 0.667 Recall 1.0\n",
      "\n",
      "08/23/17 07:07:36 Sample 47 of 50 Precision 0.5 Recall 1.0\n",
      "\n",
      "08/23/17 07:10:47 Sample 48 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/23/17 07:13:56 Sample 49 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/23/17 07:14:08 UserID 55 Test: Precision 1.0 Recall 0.6\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98        45\n",
      "        1.0       1.00      0.60      0.75         5\n",
      "\n",
      "avg / total       0.96      0.96      0.96        50\n",
      "\n",
      "08/23/17 07:14:08 User 5 UserID 52 (Total plays [6025])\n",
      "08/23/17 07:17:22 Sample 0 of 50 Precision 0.714 Recall 0.625\n",
      "\n",
      "08/23/17 07:20:36 Sample 1 of 50 Precision 0.5 Recall 0.625\n",
      "\n",
      "08/23/17 07:23:46 Sample 2 of 50 Precision 0.667 Recall 0.889\n",
      "\n",
      "08/23/17 07:27:01 Sample 3 of 50 Precision 0.625 Recall 0.833\n",
      "\n",
      "08/23/17 07:30:13 Sample 4 of 50 Precision 0.444 Recall 0.667\n",
      "\n",
      "08/23/17 07:33:23 Sample 5 of 50 Precision 0.4 Recall 0.5\n",
      "\n",
      "08/23/17 07:36:39 Sample 6 of 50 Precision 0.333 Recall 0.333\n",
      "\n",
      "08/23/17 07:39:54 Sample 7 of 50 Precision 0.429 Recall 0.5\n",
      "\n",
      "08/23/17 07:43:10 Sample 8 of 50 Precision 0.778 Recall 0.636\n",
      "\n",
      "08/23/17 07:46:22 Sample 9 of 50 Precision 0.667 Recall 1.0\n",
      "\n",
      "08/23/17 07:49:35 Sample 10 of 50 Precision 0.625 Recall 0.625\n",
      "\n",
      "08/23/17 07:52:43 Sample 11 of 50 Precision 0.625 Recall 0.833\n",
      "\n",
      "08/23/17 07:55:55 Sample 12 of 50 Precision 0.375 Recall 0.5\n",
      "\n",
      "08/23/17 07:59:07 Sample 13 of 50 Precision 0.455 Recall 0.5\n",
      "\n",
      "08/23/17 08:02:16 Sample 14 of 50 Precision 0.667 Recall 0.75\n",
      "\n",
      "08/23/17 08:05:24 Sample 15 of 50 Precision 0.786 Recall 0.786\n",
      "\n",
      "08/23/17 08:08:40 Sample 16 of 50 Precision 0.286 Recall 0.5\n",
      "\n",
      "08/23/17 08:11:53 Sample 17 of 50 Precision 1.0 Recall 0.25\n",
      "\n",
      "08/23/17 08:15:00 Sample 18 of 50 Precision 0.5 Recall 0.8\n",
      "\n",
      "08/23/17 08:18:13 Sample 19 of 50 Precision 0.5 Recall 0.667\n",
      "\n",
      "08/23/17 08:21:32 Sample 20 of 50 Precision 0.545 Recall 0.857\n",
      "\n",
      "08/23/17 08:24:44 Sample 21 of 50 Precision 0.714 Recall 1.0\n",
      "\n",
      "08/23/17 08:27:54 Sample 22 of 50 Precision 0.5 Recall 0.2\n",
      "\n",
      "08/23/17 08:31:06 Sample 23 of 50 Precision 0.6 Recall 1.0\n",
      "\n",
      "08/23/17 08:34:19 Sample 24 of 50 Precision 0.583 Recall 0.778\n",
      "\n",
      "08/23/17 08:37:30 Sample 25 of 50 Precision 0.636 Recall 0.778\n",
      "\n",
      "08/23/17 08:40:46 Sample 26 of 50 Precision 0.375 Recall 0.5\n",
      "\n",
      "08/23/17 08:44:04 Sample 27 of 50 Precision 0.615 Recall 0.8\n",
      "\n",
      "08/23/17 08:47:14 Sample 28 of 50 Precision 0.6 Recall 0.75\n",
      "\n",
      "08/23/17 08:50:30 Sample 29 of 50 Precision 0.714 Recall 0.714\n",
      "\n",
      "08/23/17 08:53:39 Sample 30 of 50 Precision 0.75 Recall 0.6\n",
      "\n",
      "08/23/17 08:57:27 Sample 31 of 50 Precision 0.818 Recall 0.9\n",
      "\n",
      "08/23/17 09:02:03 Sample 32 of 50 Precision 0.75 Recall 0.6\n",
      "\n",
      "08/23/17 09:05:15 Sample 33 of 50 Precision 0.667 Recall 0.727\n",
      "\n",
      "08/23/17 09:08:29 Sample 34 of 50 Precision 0.714 Recall 0.714\n",
      "\n",
      "08/23/17 09:11:43 Sample 35 of 50 Precision 0.647 Recall 0.733\n",
      "\n",
      "08/23/17 09:14:57 Sample 36 of 50 Precision 0.222 Recall 0.222\n",
      "\n",
      "08/23/17 09:18:14 Sample 37 of 50 Precision 0.769 Recall 0.909\n",
      "\n",
      "08/23/17 09:21:32 Sample 38 of 50 Precision 0.5 Recall 0.5\n",
      "\n",
      "08/23/17 09:24:42 Sample 39 of 50 Precision 0.556 Recall 0.556\n",
      "\n",
      "08/23/17 09:28:14 Sample 40 of 50 Precision 0.6 Recall 0.75\n",
      "\n",
      "08/23/17 09:33:02 Sample 41 of 50 Precision 0.5 Recall 0.667\n",
      "\n",
      "08/23/17 09:36:13 Sample 42 of 50 Precision 0.429 Recall 0.375\n",
      "\n",
      "08/23/17 09:39:29 Sample 43 of 50 Precision 0.7 Recall 0.636\n",
      "\n",
      "08/23/17 09:42:42 Sample 44 of 50 Precision 0.667 Recall 0.8\n",
      "\n",
      "08/23/17 09:45:52 Sample 45 of 50 Precision 0.571 Recall 0.8\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/23/17 09:49:05 Sample 46 of 50 Precision 0.6 Recall 0.75\n",
      "\n",
      "08/23/17 09:52:19 Sample 47 of 50 Precision 0.375 Recall 0.75\n",
      "\n",
      "08/23/17 09:55:30 Sample 48 of 50 Precision 0.667 Recall 0.75\n",
      "\n",
      "08/23/17 09:58:44 Sample 49 of 50 Precision 0.714 Recall 0.714\n",
      "\n",
      "08/23/17 09:58:54 UserID 52 Test: Precision 0.444 Recall 0.571\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.88      0.90        43\n",
      "        1.0       0.44      0.57      0.50         7\n",
      "\n",
      "avg / total       0.86      0.84      0.85        50\n",
      "\n",
      "08/23/17 09:58:54 User 6 UserID 96 (Total plays [2336])\n",
      "08/23/17 10:02:08 Sample 0 of 50 Precision 0.5 Recall 0.5\n",
      "\n",
      "08/23/17 10:05:23 Sample 1 of 50 Precision 0.75 Recall 0.75\n",
      "\n",
      "08/23/17 10:08:36 Sample 2 of 50 Precision 1.0 Recall 0.667\n",
      "\n",
      "08/23/17 10:11:48 Sample 3 of 50 Precision 0.4 Recall 0.5\n",
      "\n",
      "08/23/17 10:15:01 Sample 4 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 10:18:14 Sample 5 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 10:21:31 Sample 6 of 50 Precision 0.4 Recall 0.667\n",
      "\n",
      "08/23/17 10:24:51 Sample 7 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 10:28:09 Sample 8 of 50 Precision 1.0 Recall 0.75\n",
      "\n",
      "08/23/17 10:31:25 Sample 9 of 50 Precision 0.25 Recall 0.5\n",
      "\n",
      "08/23/17 10:34:37 Sample 10 of 50 Precision 0.5 Recall 0.429\n",
      "\n",
      "08/23/17 10:37:47 Sample 11 of 50 Precision 1.0 Recall 0.833\n",
      "\n",
      "08/23/17 10:41:01 Sample 12 of 50 Precision 1.0 Recall 0.667\n",
      "\n",
      "08/23/17 10:44:11 Sample 13 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 10:47:19 Sample 14 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/23/17 10:50:23 Sample 15 of 50 Precision 0.667 Recall 0.8\n",
      "\n",
      "08/23/17 10:53:33 Sample 16 of 50 Precision 0.667 Recall 1.0\n",
      "\n",
      "08/23/17 10:58:09 Sample 17 of 50 Precision 0.667 Recall 0.5\n",
      "\n",
      "08/23/17 11:01:55 Sample 18 of 50 Precision 0.667 Recall 0.667\n",
      "\n",
      "08/23/17 11:05:11 Sample 19 of 50 Precision 0.833 Recall 0.833\n",
      "\n",
      "08/23/17 11:08:34 Sample 20 of 50 Precision 0.667 Recall 1.0\n",
      "\n",
      "08/23/17 11:11:41 Sample 21 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 11:16:32 Sample 22 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 11:20:14 Sample 23 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 11:23:31 Sample 24 of 50 Precision 0.75 Recall 0.75\n",
      "\n",
      "08/23/17 11:26:44 Sample 25 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 11:30:00 Sample 26 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 11:33:17 Sample 27 of 50 Precision 0.333 Recall 1.0\n",
      "\n",
      "08/23/17 11:36:28 Sample 28 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 11:39:44 Sample 29 of 50 Precision 0.5 Recall 0.5\n",
      "\n",
      "08/23/17 11:43:03 Sample 30 of 50 Precision 0.5 Recall 1.0\n",
      "\n",
      "08/23/17 11:46:14 Sample 31 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 11:49:19 Sample 32 of 50 Precision 0.667 Recall 1.0\n",
      "\n",
      "08/23/17 11:54:02 Sample 33 of 50 Precision 0.833 Recall 1.0\n",
      "\n",
      "08/23/17 11:57:50 Sample 34 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 12:01:03 Sample 35 of 50 Precision 0.667 Recall 0.5\n",
      "\n",
      "08/23/17 12:04:16 Sample 36 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 12:07:24 Sample 37 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 12:10:38 Sample 38 of 50 Precision 1.0 Recall 0.5\n",
      "\n",
      "08/23/17 12:14:21 Sample 39 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/23/17 12:19:05 Sample 40 of 50 Precision 0.667 Recall 0.667\n",
      "\n",
      "08/23/17 12:22:17 Sample 41 of 50 Precision 1.0 Recall 0.5\n",
      "\n",
      "08/23/17 12:25:28 Sample 42 of 50 Precision 1.0 Recall 0.5\n",
      "\n",
      "08/23/17 12:28:36 Sample 43 of 50 Precision 0.8 Recall 0.8\n",
      "\n",
      "08/23/17 12:32:42 Sample 44 of 50 Precision 0.333 Recall 0.5\n",
      "\n",
      "08/23/17 12:36:30 Sample 45 of 50 Precision 0.667 Recall 0.286\n",
      "\n",
      "08/23/17 12:43:09 Sample 46 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 12:48:18 Sample 47 of 50 Precision 0.5 Recall 0.333\n",
      "\n",
      "08/23/17 12:51:28 Sample 48 of 50 Precision 1.0 Recall 0.333\n",
      "\n",
      "08/23/17 12:54:38 Sample 49 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 12:54:48 UserID 96 Test: Precision 0.0 Recall 0.0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99        49\n",
      "        1.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.96      0.98      0.97        50\n",
      "\n",
      "08/23/17 12:54:49 User 7 UserID 67 (Total plays [9648])\n",
      "08/23/17 12:58:02 Sample 0 of 50 Precision 0.778 Recall 1.0\n",
      "\n",
      "08/23/17 13:01:08 Sample 1 of 50 Precision 0.429 Recall 0.75\n",
      "\n",
      "08/23/17 13:04:44 Sample 2 of 50 Precision 0.45 Recall 0.9\n",
      "\n",
      "08/23/17 13:07:41 Sample 3 of 50 Precision 0.4 Recall 0.5\n",
      "\n",
      "08/23/17 13:10:33 Sample 4 of 50 Precision 0.333 Recall 0.4\n",
      "\n",
      "08/23/17 13:13:38 Sample 5 of 50 Precision 0.6 Recall 1.0\n",
      "\n",
      "08/23/17 13:16:40 Sample 6 of 50 Precision 0.636 Recall 0.778\n",
      "\n",
      "08/23/17 13:19:42 Sample 7 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/23/17 13:22:40 Sample 8 of 50 Precision 0.75 Recall 0.75\n",
      "\n",
      "08/23/17 13:25:36 Sample 9 of 50 Precision 0.429 Recall 0.6\n",
      "\n",
      "08/23/17 13:28:35 Sample 10 of 50 Precision 0.625 Recall 0.714\n",
      "\n",
      "08/23/17 13:31:32 Sample 11 of 50 Precision 0.6 Recall 1.0\n",
      "\n",
      "08/23/17 13:34:24 Sample 12 of 50 Precision 0.545 Recall 1.0\n",
      "\n",
      "08/23/17 13:37:20 Sample 13 of 50 Precision 0.5 Recall 0.625\n",
      "\n",
      "08/23/17 13:40:23 Sample 14 of 50 Precision 0.778 Recall 0.778\n",
      "\n",
      "08/23/17 13:43:25 Sample 15 of 50 Precision 0.714 Recall 0.714\n",
      "\n",
      "08/23/17 13:46:20 Sample 16 of 50 Precision 0.75 Recall 0.857\n",
      "\n",
      "08/23/17 13:49:12 Sample 17 of 50 Precision 0.455 Recall 0.833\n",
      "\n",
      "08/23/17 13:52:09 Sample 18 of 50 Precision 0.417 Recall 0.625\n",
      "\n",
      "08/23/17 13:55:06 Sample 19 of 50 Precision 0.4 Recall 0.571\n",
      "\n",
      "08/23/17 13:57:56 Sample 20 of 50 Precision 0.6 Recall 0.818\n",
      "\n",
      "08/23/17 14:00:47 Sample 21 of 50 Precision 0.857 Recall 0.75\n",
      "\n",
      "08/23/17 14:03:37 Sample 22 of 50 Precision 0.333 Recall 0.4\n",
      "\n",
      "08/23/17 14:06:33 Sample 23 of 50 Precision 0.571 Recall 0.571\n",
      "\n",
      "08/23/17 14:09:24 Sample 24 of 50 Precision 0.333 Recall 0.667\n",
      "\n",
      "08/23/17 14:12:14 Sample 25 of 50 Precision 0.889 Recall 0.727\n",
      "\n",
      "08/23/17 14:15:13 Sample 26 of 50 Precision 1.0 Recall 0.6\n",
      "\n",
      "08/23/17 14:18:16 Sample 27 of 50 Precision 0.714 Recall 0.556\n",
      "\n",
      "08/23/17 14:21:14 Sample 28 of 50 Precision 0.4 Recall 0.5\n",
      "\n",
      "08/23/17 14:24:10 Sample 29 of 50 Precision 0.714 Recall 0.714\n",
      "\n",
      "08/23/17 14:27:00 Sample 30 of 50 Precision 0.5 Recall 0.75\n",
      "\n",
      "08/23/17 14:29:54 Sample 31 of 50 Precision 0.909 Recall 0.909\n",
      "\n",
      "08/23/17 14:32:56 Sample 32 of 50 Precision 0.667 Recall 0.667\n",
      "\n",
      "08/23/17 14:35:55 Sample 33 of 50 Precision 0.5 Recall 0.333\n",
      "\n",
      "08/23/17 14:39:56 Sample 34 of 50 Precision 0.6 Recall 0.75\n",
      "\n",
      "08/23/17 14:43:08 Sample 35 of 50 Precision 0.625 Recall 1.0\n",
      "\n",
      "08/23/17 14:46:20 Sample 36 of 50 Precision 0.429 Recall 0.5\n",
      "\n",
      "08/23/17 14:49:32 Sample 37 of 50 Precision 0.286 Recall 0.4\n",
      "\n",
      "08/23/17 14:52:41 Sample 38 of 50 Precision 0.778 Recall 0.778\n",
      "\n",
      "08/23/17 14:55:49 Sample 39 of 50 Precision 0.6 Recall 0.75\n",
      "\n",
      "08/23/17 14:59:00 Sample 40 of 50 Precision 0.667 Recall 0.8\n",
      "\n",
      "08/23/17 15:02:15 Sample 41 of 50 Precision 0.556 Recall 0.714\n",
      "\n",
      "08/23/17 15:05:28 Sample 42 of 50 Precision 0.444 Recall 0.667\n",
      "\n",
      "08/23/17 15:08:43 Sample 43 of 50 Precision 0.786 Recall 0.917\n",
      "\n",
      "08/23/17 15:11:53 Sample 44 of 50 Precision 0.636 Recall 1.0\n",
      "\n",
      "08/23/17 15:14:59 Sample 45 of 50 Precision 0.625 Recall 0.455\n",
      "\n",
      "08/23/17 15:17:58 Sample 46 of 50 Precision 0.857 Recall 0.857\n",
      "\n",
      "08/23/17 15:21:00 Sample 47 of 50 Precision 0.286 Recall 0.4\n",
      "\n",
      "08/23/17 15:23:57 Sample 48 of 50 Precision 0.8 Recall 0.571\n",
      "\n",
      "08/23/17 15:26:56 Sample 49 of 50 Precision 0.667 Recall 0.667\n",
      "\n",
      "08/23/17 15:27:06 UserID 67 Test: Precision 0.889 Recall 0.667\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.97      0.94        38\n",
      "        1.0       0.89      0.67      0.76        12\n",
      "\n",
      "avg / total       0.90      0.90      0.89        50\n",
      "\n",
      "08/23/17 15:27:06 User 8 UserID 19 (Total plays [4443])\n",
      "08/23/17 15:29:57 Sample 0 of 50 Precision 0.25 Recall 0.25\n",
      "\n",
      "08/23/17 15:32:56 Sample 1 of 50 Precision 1.0 Recall 0.6\n",
      "\n",
      "08/23/17 15:35:48 Sample 2 of 50 Precision 0.5 Recall 0.5\n",
      "\n",
      "08/23/17 15:39:05 Sample 3 of 50 Precision 1.0 Recall 0.333\n",
      "\n",
      "08/23/17 15:42:14 Sample 4 of 50 Precision 0.833 Recall 0.714\n",
      "\n",
      "08/23/17 15:47:34 Sample 5 of 50 Precision 0.667 Recall 0.667\n",
      "\n",
      "08/23/17 15:50:36 Sample 6 of 50 Precision 0.75 Recall 0.6\n",
      "\n",
      "08/23/17 15:55:47 Sample 7 of 50 Precision 0.667 Recall 0.857\n",
      "\n",
      "08/23/17 15:58:42 Sample 8 of 50 Precision 0.75 Recall 0.6\n",
      "\n",
      "08/23/17 16:03:51 Sample 9 of 50 Precision 0.6 Recall 0.6\n",
      "\n",
      "08/23/17 16:07:18 Sample 10 of 50 Precision 0.6 Recall 1.0\n",
      "\n",
      "08/23/17 16:10:27 Sample 11 of 50 Precision 0.5 Recall 0.667\n",
      "\n",
      "08/23/17 16:13:35 Sample 12 of 50 Precision 0.6 Recall 0.375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/23/17 16:16:34 Sample 13 of 50 Precision 0.333 Recall 0.25\n",
      "\n",
      "08/23/17 16:19:36 Sample 14 of 50 Precision 1.0 Recall 0.8\n",
      "\n",
      "08/23/17 16:22:52 Sample 15 of 50 Precision 0.333 Recall 1.0\n",
      "\n",
      "08/23/17 16:25:56 Sample 16 of 50 Precision 0.625 Recall 0.714\n",
      "\n",
      "08/23/17 16:28:57 Sample 17 of 50 Precision 0.5 Recall 1.0\n",
      "\n",
      "08/23/17 16:32:07 Sample 18 of 50 Precision 0.667 Recall 0.857\n",
      "\n",
      "08/23/17 16:35:07 Sample 19 of 50 Precision 0.333 Recall 0.667\n",
      "\n",
      "08/23/17 16:38:07 Sample 20 of 50 Precision 0.5 Recall 0.6\n",
      "\n",
      "08/23/17 16:41:12 Sample 21 of 50 Precision 0.5 Recall 0.5\n",
      "\n",
      "08/23/17 16:44:11 Sample 22 of 50 Precision 0.4 Recall 0.667\n",
      "\n",
      "08/23/17 16:47:13 Sample 23 of 50 Precision 1.0 Recall 0.75\n",
      "\n",
      "08/23/17 16:50:19 Sample 24 of 50 Precision 0.75 Recall 0.75\n",
      "\n",
      "08/23/17 16:53:29 Sample 25 of 50 Precision 0.636 Recall 0.875\n",
      "\n",
      "08/23/17 16:56:34 Sample 26 of 50 Precision 0.4 Recall 0.5\n",
      "\n",
      "08/23/17 16:59:40 Sample 27 of 50 Precision 0.5 Recall 0.333\n",
      "\n",
      "08/23/17 17:02:38 Sample 28 of 50 Precision 0.8 Recall 0.571\n",
      "\n",
      "08/23/17 17:05:41 Sample 29 of 50 Precision 0.6 Recall 0.6\n",
      "\n",
      "08/23/17 17:09:19 Sample 30 of 50 Precision 0.5 Recall 0.75\n",
      "\n",
      "08/23/17 17:13:44 Sample 31 of 50 Precision 0.5 Recall 1.0\n",
      "\n",
      "08/23/17 17:16:50 Sample 32 of 50 Precision 0.75 Recall 1.0\n",
      "\n",
      "08/23/17 17:19:46 Sample 33 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 17:23:35 Sample 34 of 50 Precision 1.0 Recall 1.0\n",
      "\n",
      "08/23/17 17:26:40 Sample 35 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 17:31:45 Sample 36 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 17:34:44 Sample 37 of 50 Precision 1.0 Recall 0.333\n",
      "\n",
      "08/23/17 17:37:44 Sample 38 of 50 Precision 0.25 Recall 0.5\n",
      "\n",
      "08/23/17 17:42:12 Sample 39 of 50 Precision 0.5 Recall 1.0\n",
      "\n",
      "08/23/17 17:45:51 Sample 40 of 50 Precision 0.5 Recall 0.333\n",
      "\n",
      "08/23/17 17:48:50 Sample 41 of 50 Precision 0.556 Recall 0.714\n",
      "\n",
      "08/23/17 17:51:52 Sample 42 of 50 Precision 0.4 Recall 0.667\n",
      "\n",
      "08/23/17 17:54:50 Sample 43 of 50 Precision 0.5 Recall 0.333\n",
      "\n",
      "08/23/17 17:59:20 Sample 44 of 50 Precision 0.5 Recall 1.0\n",
      "\n",
      "08/23/17 18:02:26 Sample 45 of 50 Precision 1.0 Recall 0.5\n",
      "\n",
      "08/23/17 18:06:44 Sample 46 of 50 Precision 0.5 Recall 0.667\n",
      "\n",
      "08/23/17 18:09:48 Sample 47 of 50 Precision 0.429 Recall 1.0\n",
      "\n",
      "08/23/17 18:14:55 Sample 48 of 50 Precision 0.4 Recall 1.0\n",
      "\n",
      "08/23/17 18:17:55 Sample 49 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 18:18:05 UserID 19 Test: Precision 0.75 Recall 0.6\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.98      0.97        45\n",
      "        1.0       0.75      0.60      0.67         5\n",
      "\n",
      "avg / total       0.94      0.94      0.94        50\n",
      "\n",
      "08/23/17 18:18:06 User 9 UserID 95 (Total plays [8217])\n",
      "08/23/17 18:22:36 Sample 0 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 18:25:41 Sample 1 of 50 Precision 0.24 Recall 1.0\n",
      "\n",
      "08/23/17 18:28:54 Sample 2 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 18:31:52 Sample 3 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 18:35:25 Sample 4 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 18:38:23 Sample 5 of 50 Precision 0.24 Recall 1.0\n",
      "\n",
      "08/23/17 18:41:20 Sample 6 of 50 Precision 0.24 Recall 1.0\n",
      "\n",
      "08/23/17 18:44:11 Sample 7 of 50 Precision 0.364 Recall 0.364\n",
      "\n",
      "08/23/17 18:47:02 Sample 8 of 50 Precision 0.18 Recall 1.0\n",
      "\n",
      "08/23/17 18:49:53 Sample 9 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 18:52:49 Sample 10 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 18:55:43 Sample 11 of 50 Precision 0.34 Recall 1.0\n",
      "\n",
      "08/23/17 18:59:17 Sample 12 of 50 Precision 0.458 Recall 0.733\n",
      "\n",
      "08/23/17 19:02:20 Sample 13 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 19:05:22 Sample 14 of 50 Precision 0.28 Recall 1.0\n",
      "\n",
      "08/23/17 19:08:15 Sample 15 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 19:11:07 Sample 16 of 50 Precision 0.28 Recall 1.0\n",
      "\n",
      "08/23/17 19:14:16 Sample 17 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 19:17:19 Sample 18 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 19:20:45 Sample 19 of 50 Precision 0.3 Recall 1.0\n",
      "\n",
      "08/23/17 19:24:15 Sample 20 of 50 Precision 0.3 Recall 1.0\n",
      "\n",
      "08/23/17 19:29:04 Sample 21 of 50 Precision 0.26 Recall 1.0\n",
      "\n",
      "08/23/17 19:32:27 Sample 22 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 19:35:24 Sample 23 of 50 Precision 0.34 Recall 1.0\n",
      "\n",
      "08/23/17 19:40:15 Sample 24 of 50 Precision 0.2 Recall 1.0\n",
      "\n",
      "08/23/17 19:43:39 Sample 25 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 19:46:56 Sample 26 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 19:50:06 Sample 27 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 19:53:20 Sample 28 of 50 Precision 0.3 Recall 1.0\n",
      "\n",
      "08/23/17 19:56:41 Sample 29 of 50 Precision 0.22 Recall 1.0\n",
      "\n",
      "08/23/17 20:00:04 Sample 30 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 20:03:17 Sample 31 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 20:06:32 Sample 32 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 20:09:43 Sample 33 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 20:13:07 Sample 34 of 50 Precision 0.38 Recall 1.0\n",
      "\n",
      "08/23/17 20:16:20 Sample 35 of 50 Precision 0.16 Recall 1.0\n",
      "\n",
      "08/23/17 20:19:33 Sample 36 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 20:22:54 Sample 37 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 20:26:14 Sample 38 of 50 Precision 0.28 Recall 1.0\n",
      "\n",
      "08/23/17 20:29:36 Sample 39 of 50 Precision 0.22 Recall 1.0\n",
      "\n",
      "08/23/17 20:32:44 Sample 40 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 20:38:05 Sample 41 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 20:41:18 Sample 42 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 20:44:26 Sample 43 of 50 Precision 0.24 Recall 1.0\n",
      "\n",
      "08/23/17 20:47:28 Sample 44 of 50 Precision 0.26 Recall 1.0\n",
      "\n",
      "08/23/17 20:52:32 Sample 45 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 20:55:39 Sample 46 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 21:00:02 Sample 47 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 21:04:10 Sample 48 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 21:07:25 Sample 49 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 21:07:34 UserID 95 Test: Precision 0.0 Recall 0.0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      1.00      0.97        47\n",
      "        1.0       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.88      0.94      0.91        50\n",
      "\n",
      "08/23/17 21:07:35 User 10 UserID 32 (Total plays [3824])\n",
      "08/23/17 21:10:38 Sample 0 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 21:15:55 Sample 1 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 21:19:09 Sample 2 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 21:22:17 Sample 3 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 21:27:31 Sample 4 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 21:30:46 Sample 5 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 21:34:02 Sample 6 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 21:37:08 Sample 7 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 21:40:54 Sample 8 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 21:45:18 Sample 9 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 21:48:35 Sample 10 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 21:51:39 Sample 11 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 21:56:03 Sample 12 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 21:59:52 Sample 13 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 22:02:57 Sample 14 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 22:07:28 Sample 15 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 22:11:02 Sample 16 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 22:14:34 Sample 17 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 22:19:18 Sample 18 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 22:22:35 Sample 19 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 22:25:45 Sample 20 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 22:28:58 Sample 21 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 22:33:08 Sample 22 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 22:37:18 Sample 23 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 22:40:38 Sample 24 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 22:43:53 Sample 25 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 22:47:17 Sample 26 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 22:50:33 Sample 27 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 22:53:57 Sample 28 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 22:57:10 Sample 29 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 23:00:18 Sample 30 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 23:05:23 Sample 31 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 23:08:41 Sample 32 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 23:12:05 Sample 33 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 23:15:20 Sample 34 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 23:18:43 Sample 35 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 23:22:06 Sample 36 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 23:25:28 Sample 37 of 50 Precision 0.0 Recall 0.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/23/17 23:28:46 Sample 38 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 23:31:59 Sample 39 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 23:35:15 Sample 40 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 23:38:29 Sample 41 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 23:41:42 Sample 42 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 23:44:52 Sample 43 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 23:48:10 Sample 44 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 23:51:11 Sample 45 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 23:55:48 Sample 46 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/23/17 23:59:38 Sample 47 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 00:02:49 Sample 48 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 00:06:05 Sample 49 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 00:06:17 UserID 32 Test: Precision 0.0 Recall 0.0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98        48\n",
      "        1.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.92      0.96      0.94        50\n",
      "\n",
      "08/24/17 00:06:17 User 11 UserID 6 (Total plays [7652])\n",
      "08/24/17 00:09:42 Sample 0 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 00:13:01 Sample 1 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 00:16:10 Sample 2 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 00:19:27 Sample 3 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 00:22:44 Sample 4 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 00:26:07 Sample 5 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 00:29:28 Sample 6 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 00:32:50 Sample 7 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 00:36:02 Sample 8 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 00:39:13 Sample 9 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 00:42:24 Sample 10 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 00:45:40 Sample 11 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 00:48:54 Sample 12 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 00:52:05 Sample 13 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 00:55:27 Sample 14 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 00:58:46 Sample 15 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 01:02:00 Sample 16 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 01:05:12 Sample 17 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 01:08:30 Sample 18 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 01:11:52 Sample 19 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 01:15:08 Sample 20 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 01:18:22 Sample 21 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 01:21:44 Sample 22 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 01:25:07 Sample 23 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 01:28:24 Sample 24 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 01:31:40 Sample 25 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 01:35:06 Sample 26 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 01:38:27 Sample 27 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 01:41:53 Sample 28 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 01:45:11 Sample 29 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 01:48:27 Sample 30 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 01:51:52 Sample 31 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 01:55:13 Sample 32 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 01:58:23 Sample 33 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 02:01:39 Sample 34 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 02:05:02 Sample 35 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 02:08:23 Sample 36 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 02:11:50 Sample 37 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 02:15:17 Sample 38 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 02:18:38 Sample 39 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 02:22:03 Sample 40 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 02:25:27 Sample 41 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 02:28:52 Sample 42 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 02:32:14 Sample 43 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 02:35:28 Sample 44 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 02:38:54 Sample 45 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 02:42:21 Sample 46 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 02:45:43 Sample 47 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 02:49:07 Sample 48 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 02:52:44 Sample 49 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 02:52:55 UserID 6 Test: Precision 0.0 Recall 0.0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99        49\n",
      "        1.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.96      0.98      0.97        50\n",
      "\n",
      "08/24/17 02:52:55 User 12 UserID 60 (Total plays [3839])\n",
      "08/24/17 02:56:23 Sample 0 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 02:59:48 Sample 1 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 03:03:13 Sample 2 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 03:06:34 Sample 3 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 03:09:52 Sample 4 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 03:13:09 Sample 5 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 03:16:27 Sample 6 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 03:19:51 Sample 7 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 03:23:16 Sample 8 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 03:26:32 Sample 9 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 03:29:55 Sample 10 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 03:33:09 Sample 11 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 03:36:26 Sample 12 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 03:39:45 Sample 13 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 03:42:58 Sample 14 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 03:46:17 Sample 15 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 03:49:36 Sample 16 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 03:53:01 Sample 17 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 03:56:22 Sample 18 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 03:59:35 Sample 19 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 04:03:01 Sample 20 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 04:06:19 Sample 21 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 04:09:45 Sample 22 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 04:13:03 Sample 23 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 04:16:20 Sample 24 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 04:19:34 Sample 25 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 04:23:01 Sample 26 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 04:26:27 Sample 27 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 04:29:47 Sample 28 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 04:33:09 Sample 29 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 04:36:29 Sample 30 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 04:39:50 Sample 31 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 04:43:00 Sample 32 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 04:46:12 Sample 33 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 04:49:23 Sample 34 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 04:52:41 Sample 35 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 04:55:53 Sample 36 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 04:59:05 Sample 37 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 05:02:22 Sample 38 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 05:05:40 Sample 39 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 05:09:02 Sample 40 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 05:12:28 Sample 41 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 05:15:46 Sample 42 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 05:19:09 Sample 43 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 05:22:26 Sample 44 of 50 Precision 0.0 Recall 0.0\n",
      "\n",
      "08/24/17 05:25:50 Sample 45 of 50 Precision 0.0 Recall 0.0\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-8895057b0e19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mResetModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0minitializeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatureLen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass1Weighting\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloadFromSave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mTrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprintOnBatchIteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprintOnSampleIteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mTestModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-face78c9a8e5>\u001b[0m in \u001b[0;36mTrainModel\u001b[0;34m(printOnBatchIteration, printOnSampleIteration, enableLogging, _saveModel)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_Iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Num of times to iterate over the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainModel_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mprintOnBatchIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-8f8db5e748cd>\u001b[0m in \u001b[0;36mtrainModel_1\u001b[0;34m(batch_x, batch_y)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m##############################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrainModel_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Calculate loss & accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###### Model setup\n",
    "loadFromSave = False\n",
    "user_iteration = 10      # How many iterations of user selection\n",
    "samplesPerUser = 20      # How many times to randomly sample from each user\n",
    "batchRows = 50           # How many periods to select sample (batch size)\n",
    "batch_Iterations = 5    # How many iterations to perform on one batch\n",
    "\n",
    "n_steps = 672         # How many time steps (i.e. depth) to have\n",
    "learning_rate = 0.002\n",
    "n_hidden = 250 # hidden layer num of features\n",
    "n_layers = 4\n",
    "class1Weighting = 4\n",
    "n_classes = 2  # 2 for one-hot\n",
    "cellType = \"LSTMCell\"  # Choose: TimeFreqLSTMCell BasicLSTMCell\n",
    "#fieldList=\"UserID, t, HrsFrom5pm, isSun,isMon,isTue,isWed,isThu,isFri,isSat, t1,t2, t23_5hrs,t24hrs,t24_5hrs\"\n",
    "fieldList=\"UserID, t, t1\"\n",
    "featureLen = len(fieldList.split(\",\"))-2 # -2 as we drop UserID and t\n",
    "tblName='tblTimeSeriesData'\n",
    "\n",
    "ResetModel()\n",
    "initializeModel(n_steps,featureLen,class1Weighting,loadFromSave)\n",
    "TrainModel(printOnBatchIteration=False,printOnSampleIteration=1)\n",
    "TestModel()\n",
    "\n",
    "print('Features len: {} User Iteration {} Samples per user: {} Batch iterations: {} Batch size {} N_steps {} Units {} Layers {} Weighting {}'.format(featureLen,user_iteration, samplesPerUser, batch_Iterations, batchRows, n_Steps, n_hidden, n_layers, class1Weighting))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">6. Other Methods</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datetime import datetime\n",
    "\n",
    "#from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def getData(fieldList,tblName):\n",
    "    con = sqlite3.connect(dbPath)\n",
    "    c = con.cursor()\n",
    "    # Get list of UserIDs\n",
    "    _df = pd.read_sql_query(\"Select {} from {}\".format(fieldList,tblName),con)\n",
    "    _x = _df.drop(['t'], 1).values\n",
    "    _y = _df['t'].values.astype(int)\n",
    "    con.close()\n",
    "    return _x, _y\n",
    "\n",
    "def getSample(_x,_y, _sampleSize):\n",
    "    idx = np.random.choice(np.arange(len(_x)), _sampleSize, replace=False)\n",
    "    _xSample = x[idx]\n",
    "    _ySample = y[idx]\n",
    "    return _xSample,_ySample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampleSize = 100000\n",
    "fieldList=\"t, t1,t2, t3,t4,t5 t23_5hrs,t24hrs,t24_5hrs, HrsFrom5pm, isSun,isMon,isTue,isWed,isThu,isFri,isSat\"\n",
    "x,y = getData(fieldList,'tblTimeSeriesData')\n",
    "x,y = getSample(x,y,sampleSize)\n",
    "\n",
    "# Only keep first plays\n",
    "y=(x[:,0]==0)*(x[:,1]==0)*(x[:,2]==0)*(x[:,3]==0)*y\n",
    "# Run baseline Model\n",
    "#Baseline2(x,y)\n",
    "\n",
    "#LinearKernel2(x,y,False)\n",
    "#LinearKernel2(x,y,True)\n",
    "\n",
    "#LogisticModel2(x,y,False)\n",
    "#LogisticModel2(x,y,True)\n",
    "\n",
    "RBFKernel2(x,y,False)\n",
    "RBFKernel2(x,y,True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Av. precision 0.802 +/- 0.033, Av. recall 0.695+/0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BaseLineModel(x,y):\n",
    "    # Get predictions\n",
    "    print('\\n--------------------------------------------------------')\n",
    "    print('1. Baseline model')\n",
    "    print('--------------------------------------------------------')\n",
    "\n",
    "    print(metrics.precision_score(y,x[:,8]))\n",
    "    print(metrics.recall_score(y,x[:,8]))\n",
    "    print(metrics.classification_report(y,x[:,8])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LinearKernel(x,y):\n",
    "\n",
    "    print('\\n--------------------------------------------------------')\n",
    "    print('3. Linear Kernel')\n",
    "    print('--------------------------------------------------------')\n",
    "    \n",
    "    startTime = datetime.now()\n",
    "    print('Start time {}'.format(startTime))\n",
    "\n",
    "    clf = svm.SVC(kernel='linear', C=1, random_state=0)\n",
    "    # Increase weight where t-1 is 0 and t is 1\n",
    "    sampleWeights =  1+(y[:] == 1) * (x[:,1] ==0)\n",
    "    scoring = ['precision_macro', 'recall_macro']\n",
    "    scores = cross_validate(clf, x, y, scoring=scoring,\n",
    "    cv=5, return_train_score=False, n_jobs=-1,fit_params={'sample_weight': sampleWeights})\n",
    "    #cv=5, return_train_score=False, n_jobs=-1)\n",
    "    \n",
    "\n",
    "    pMn=round(scores['test_precision_macro'].mean(),3)\n",
    "    pSd=round(scores['test_precision_macro'].std(),3)\n",
    "    rMn=round(scores['test_recall_macro'].mean(),3)\n",
    "    rSd=round(scores['test_recall_macro'].std(),3)\n",
    "    print (\"Av. precision {} +/- {}, Av. recall {}+/{},\".format(pMn,pSd,rMn,rSd))\n",
    "\n",
    "    timeElapsed=datetime.now()-startTime\n",
    "    print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "\n",
    "    #predicted = cross_val_predict(clf, x, y, cv=5, n_jobs=-1)\n",
    "    #print(metrics.roc_auc_score(y,predicted))  \n",
    "    #print(metrics.classification_report(y,predicted))  # Need to feed it yTest not yTest_OneHot here\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RBFKernel(x,y):\n",
    "\n",
    "    print('\\n--------------------------------------------------------')\n",
    "    print('3. SVM- RBF Kernel')\n",
    "    print('--------------------------------------------------------')\n",
    "    \n",
    "    startTime = datetime.now()\n",
    "    print('Start time {}'.format(startTime))\n",
    "\n",
    "    clf = svm.SVC(kernel='rbf', C=1, random_state=0)\n",
    "    # Increase weight where t-1 is 0 and t is 1\n",
    "    sampleWeights =  1+(y[:] == 1) * (x[:,1] ==0)\n",
    "    scoring = ['precision_macro', 'recall_macro']\n",
    "    scores = cross_validate(clf, x, y, scoring=scoring,\n",
    "    cv=5, return_train_score=False, n_jobs=-1,fit_params={'sample_weight': sampleWeights})\n",
    "    #cv=5, return_train_score=False, n_jobs=-1)\n",
    "    \n",
    "\n",
    "    pMn=round(scores['test_precision_macro'].mean(),3)\n",
    "    pSd=round(scores['test_precision_macro'].std(),3)\n",
    "    rMn=round(scores['test_recall_macro'].mean(),3)\n",
    "    rSd=round(scores['test_recall_macro'].std(),3)\n",
    "    print (\"Av. precision {} +/- {}, Av. recall {}+/{},\".format(pMn,pSd,rMn,rSd))\n",
    "\n",
    "    timeElapsed=datetime.now()-startTime\n",
    "    print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "\n",
    "    #predicted = cross_val_predict(clf, x, y, cv=5, n_jobs=-1)\n",
    "    #print(metrics.roc_auc_score(y,predicted))  \n",
    "    #print(metrics.classification_report(y,predicted))  # Need to feed it yTest not yTest_OneHot here\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LogisticModel(x,y):\n",
    "\n",
    "    print('\\n--------------------------------------------------------')\n",
    "    print('4. Logistic Model')\n",
    "    print('--------------------------------------------------------')\n",
    "    \n",
    "    startTime = datetime.now()\n",
    "    print('Start time {}'.format(startTime))\n",
    "\n",
    "    clf = LogisticRegression(C=1,class_weight ='balanced')\n",
    "    # Increase weight where t-1 is 0 and t is 1\n",
    "    sampleWeights =  1+(y[:] == 1) * (x[:,1] ==0)\n",
    "    scoring = ['precision_macro', 'recall_macro']\n",
    "    scores = cross_validate(clf, x, y, scoring=scoring,cv=5, return_train_score=False, n_jobs=-1)\n",
    "    \n",
    "    pMn=round(scores['test_precision_macro'].mean(),3)\n",
    "    pSd=round(scores['test_precision_macro'].std(),3)\n",
    "    rMn=round(scores['test_recall_macro'].mean(),3)\n",
    "    rSd=round(scores['test_recall_macro'].std(),3)\n",
    "    print (\"Av. precision {} +/- {}, Av. recall {}+/{},\".format(pMn,pSd,rMn,rSd))\n",
    "\n",
    "    timeElapsed=datetime.now()-startTime\n",
    "    print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Baseline2(x,y):\n",
    "\n",
    "    print('\\n--------------------------------------------------------')\n",
    "    print('3. Baseline')\n",
    "    print('--------------------------------------------------------')\n",
    "    \n",
    "    startTime = datetime.now()\n",
    "    print('Start time {}'.format(startTime))\n",
    "    prec= np.zeros(5)\n",
    "    rec = np.zeros(5)\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        xTrain, xTest = x[train_index], x[test_index]\n",
    "        yTrain, yTest = y[train_index], y[test_index]\n",
    "        \n",
    "        pred = xTest[:,8]\n",
    "        prec[i],rec[i], _, _ = metrics.precision_recall_fscore_support(yTest,pred, average='binary') \n",
    "        \n",
    "        #print (metrics.classification_report(yTest,pred))\n",
    "        i+=1\n",
    "    \n",
    "    pMn=round(prec.mean(),3)\n",
    "    pSd=round(prec.std(),3)\n",
    "    rMn=round(rec.mean(),3)\n",
    "    rSd=round(rec.std(),3)\n",
    "    print (\"Av. precision {} +/- {}, Av. recall {}+/{},\".format(pMn,pSd,rMn,rSd))\n",
    "\n",
    "    timeElapsed=datetime.now()-startTime\n",
    "    print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LinearKernel2(x,y,weighted):\n",
    "\n",
    "    print('\\n--------------------------------------------------------')\n",
    "    print('3. Linear Kernel (weighted = {})'.format(weighted))\n",
    "    print('--------------------------------------------------------')\n",
    "    \n",
    "    startTime = datetime.now()\n",
    "    print('Start time {}'.format(startTime))\n",
    "\n",
    "    clf = svm.SVC(kernel='linear', C=1, random_state=0)\n",
    "    # Increase weight where t-1 is 0 and t is 1\n",
    "    \n",
    "    prec= np.zeros(5)\n",
    "    rec = np.zeros(5)\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        xTrain, xTest = x[train_index], x[test_index]\n",
    "        yTrain, yTest = y[train_index], y[test_index]\n",
    "        \n",
    "        clf.fit(xTrain,yTrain)\n",
    "        pred = clf.predict(xTest)\n",
    "        \n",
    "        if weighted:\n",
    "            sampleWeights =  1+(yTest[:] == 1) * (xTest[:,1] ==0)\n",
    "            prec[i],rec[i], _, _ = metrics.precision_recall_fscore_support(yTest,pred, average='binary',sample_weight=sampleWeights) \n",
    "        else:\n",
    "            prec[i],rec[i], _, _ = metrics.precision_recall_fscore_support(yTest,pred, average='binary') \n",
    "        \n",
    "        #print (metrics.classification_report(yTest,pred))\n",
    "        i+=1\n",
    "    \n",
    "    pMn=round(prec.mean(),3)\n",
    "    pSd=round(prec.std(),3)\n",
    "    rMn=round(rec.mean(),3)\n",
    "    rSd=round(rec.std(),3)\n",
    "    print (\"Av. precision {} +/- {}, Av. recall {}+/{},\".format(pMn,pSd,rMn,rSd))\n",
    "\n",
    "    coeffs = np.reshape(np.round(clf.coef_,5),(-1,1))\n",
    "    coeffs=np.concatenate((np.reshape(fieldList.split(',')[1:],(-1,1)),coeffs),axis=1)\n",
    "    print(pd.DataFrame(coeffs,columns=['Field','Coeff']))\n",
    "    \n",
    "    timeElapsed=datetime.now()-startTime\n",
    "    print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RBFKernel2(x,y,weighted):\n",
    "\n",
    "    print('\\n--------------------------------------------------------')\n",
    "    print('4. RBF Kernel (weighted = {})'.format(weighted))\n",
    "    print('--------------------------------------------------------')\n",
    "    \n",
    "    startTime = datetime.now()\n",
    "    print('Start time {}'.format(startTime))\n",
    "\n",
    "    clf = svm.SVC(kernel='rbf', C=1, random_state=0)\n",
    "    # Increase weight where t-1 is 0 and t is 1\n",
    "    \n",
    "    prec= np.zeros(5)\n",
    "    rec = np.zeros(5)\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        xTrain, xTest = x[train_index], x[test_index]\n",
    "        yTrain, yTest = y[train_index], y[test_index]\n",
    "        \n",
    "        clf.fit(xTrain,yTrain)\n",
    "        pred = clf.predict(xTest)\n",
    "        \n",
    "        if weighted:\n",
    "            sampleWeights =  1+(yTest[:] == 1) * (xTest[:,1] ==0)\n",
    "            prec[i],rec[i], _, _ = metrics.precision_recall_fscore_support(yTest,pred, average='binary',sample_weight=sampleWeights) \n",
    "        else:\n",
    "            prec[i],rec[i], _, _ = metrics.precision_recall_fscore_support(yTest,pred, average='binary') \n",
    "        \n",
    "        #print (metrics.classification_report(yTest,pred))\n",
    "        i+=1\n",
    "    \n",
    "    pMn=round(prec.mean(),3)\n",
    "    pSd=round(prec.std(),3)\n",
    "    rMn=round(rec.mean(),3)\n",
    "    rSd=round(rec.std(),3)\n",
    "    print (\"Av. precision {} +/- {}, Av. recall {}+/{},\".format(pMn,pSd,rMn,rSd))\n",
    "    \n",
    "    timeElapsed=datetime.now()-startTime\n",
    "    print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LogisticModel2(x,y,weighted):\n",
    "\n",
    "    print('\\n--------------------------------------------------------')\n",
    "    print('4. Logistic Model (weighted = {})'.format(weighted))\n",
    "    print('--------------------------------------------------------')\n",
    "    \n",
    "    startTime = datetime.now()\n",
    "    print('Start time {}'.format(startTime))\n",
    "\n",
    "    clf = LogisticRegression(C=1,class_weight ='balanced')\n",
    "    # Increase weight where t-1 is 0 and t is 1\n",
    "    sampleWeights =  1+(y[:] == 1) * (x[:,1] ==0)\n",
    "    k=5\n",
    "    prec= np.zeros(k)\n",
    "    rec = np.zeros(k)\n",
    "    i=0\n",
    "    \n",
    "    kf = KFold(n_splits=k)\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        xTrain, xTest = x[train_index], x[test_index]\n",
    "        yTrain, yTest = y[train_index], y[test_index]\n",
    "        clf.fit(xTrain,yTrain)\n",
    "        pred = clf.predict(xTest)\n",
    "        \n",
    "        if weighted:\n",
    "            sampleWeights =  1+(yTest[:] == 1) * (xTest[:,1] ==0)\n",
    "            prec[i],rec[i], _, _ = metrics.precision_recall_fscore_support(yTest,pred, average='binary',sample_weight=sampleWeights)\n",
    "            #print (metrics.classification_report(yTest,pred))\n",
    "        else:\n",
    "            prec[i],rec[i], _, _ = metrics.precision_recall_fscore_support(yTest,pred, average='binary')\n",
    "            #print (metrics.classification_report(yTest,pred))\n",
    "        \n",
    "        i+=1\n",
    "    \n",
    "    pMn=round(prec.mean(),3)\n",
    "    pSd=round(prec.std(),3)\n",
    "    rMn=round(rec.mean(),3)\n",
    "    rSd=round(rec.std(),3)\n",
    "    print (\"Av. precision {} +/- {}, Av. recall {}+/{},\".format(pMn,pSd,rMn,rSd))\n",
    "\n",
    "    coeffs = np.reshape(np.round(clf.coef_,5),(-1,1))\n",
    "    coeffs=np.concatenate((np.reshape(fieldList.split(',')[1:],(-1,1)),coeffs),axis=1)\n",
    "    print(pd.DataFrame(coeffs,columns=['Field','Coeff']))\n",
    "    \n",
    "    timeElapsed=datetime.now()-startTime\n",
    "    print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
