{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\" style=\"background-color:#616161;color:white\">RNN Model</h1>\n",
    "\n",
    "Adapted from: https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">0. Setup</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Input Parameters</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Root path\n",
    "#root = \"C:/DS/Github/MusicRecommendation\"  # BA, Windows\n",
    "root = \"/home/badrul/git/EventPrediction\" # BA, Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Common Libraries</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "# Core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.debugger import Tracer    # Used for debugging\n",
    "import logging\n",
    "from random import *\n",
    "\n",
    "# File and database management\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "# Date/Time\n",
    "import datetime\n",
    "import time\n",
    "#from datetime import timedelta # Deprecated\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt             # Quick\n",
    "%matplotlib inline\n",
    "\n",
    "# Misc\n",
    "import random\n",
    "import importlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.basicConfig(filename='RNN.log',level=logging.DEBUG)\n",
    "\n",
    "#-------------- Custom Libs -----------------#\n",
    "os.chdir(root)\n",
    "\n",
    "# Import the codebase module\n",
    "fPath = root + \"/1_codemodule\"\n",
    "if fPath not in sys.path: sys.path.append(fPath)\n",
    "\n",
    "# Custom Libs\n",
    "import coreCode as cc\n",
    "import lastfmCode as fm\n",
    "print ('Ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Page Specific Libraries</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "# Data science (comment out if not needed)\n",
    "#from sklearn.manifold import TSNE\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "print ('Ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Load settings</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "settingsDict =  cc.loadSettings()\n",
    "dbPath = root + settingsDict['mainDbPath_sml']\n",
    "fmSimilarDbPath = root + settingsDict['fmSimilarDbPath']\n",
    "fmTagsDbPath = root + settingsDict['fmTagsDbPath']\n",
    "trackMetaDbPath = root + settingsDict['trackmetadata']\n",
    "periodGranularity = int(settingsDict['periodGranularity'])\n",
    "print ('Ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">1. Build Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases,n_steps):\n",
    "    # Current data input shape: (batchRows, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batchRows, n_input)\n",
    "    \n",
    "    # Unstack to get a list of 'n_steps' tensors of shape (batchRows, n_input)\n",
    "    x = tf.unstack(x, n_steps, 1)  # See https://stackoverflow.com/questions/45278276/tensorflow-lstm-dropout-implementation-shape-problems/45279243#45279243\n",
    "    \n",
    "    # Define a lstm cell with tensorflow\n",
    "    #lstm_cell = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "    if cellType == \"BasicLSTMCell\":\n",
    "        lstm_cell = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "        outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    elif cellType == \"TimeFreqLSTMCell\":\n",
    "        lstm_cell =rnn.TimeFreqLSTMCell(n_hidden, use_peepholes=True, feature_size= 22, forget_bias=1.0)\n",
    "        outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    elif cellType == \"GridLSTMCell\":\n",
    "        lstm_cell =rnn.GridLSTMCell(n_hidden, forget_bias=1.0)\n",
    "        outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)        \n",
    "    else:\n",
    "        print(\"Did not recognize {}\".format(cellType))\n",
    "    # Get lstm cell output\n",
    "    \n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "def _buildGraph(n_steps,n_input, classWeights = None):\n",
    "    global x, y, _pred, _predProb, _logits, _cost, optimizer, _accuracy,_correct_pred\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    # tf Graph input\n",
    "    x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "    y = tf.placeholder(\"int64\", [None])\n",
    "\n",
    "    # Define weights\n",
    "    weights = {'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))}\n",
    "    biases = {'out': tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "    # Evaluate model\n",
    "    _logits = RNN(x, weights, biases,n_steps)\n",
    "    _cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=_logits, labels=y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(_cost)\n",
    "    \n",
    "    _predProb =tf.nn.softmax(_logits)  # Convert to proper probs\n",
    "    _pred =tf.argmax(_predProb,1)  # Take the highest prob\n",
    "    _correct_pred = tf.equal(_pred, y)\n",
    "    _accuracy = tf.reduce_mean(tf.cast(_correct_pred, tf.float32))\n",
    "print('Ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ResetModel():\n",
    "    try:\n",
    "        sess.close()\n",
    "        tf.reset_default_graph()\n",
    "    except NameError:\n",
    "        return\n",
    "    \n",
    "def initializeModel():    \n",
    "    global sess\n",
    "    n_input = len(fieldList.split(\",\"))-2 # -2 as we drop UserID and t\n",
    "\n",
    "    # Build graph\n",
    "    _buildGraph(n_steps,n_input = n_input)\n",
    "\n",
    "    # Initializing the variables\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    sess = tf.Session() # Has tome come after init\n",
    "    if loadFromSave:\n",
    "        saver.restore(sess,'./3_Data/saves/model.ckpt')\n",
    "    else:\n",
    "        sess.run(init)\n",
    "    print('Model initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">2. Model Training Functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "def randomSelectFromData(_X, _Y,_batchRows = 10):\n",
    "    # Num of periodss = batch size\n",
    "    \n",
    "    # Training cycle\n",
    "    \n",
    "    XCols=np.shape(_X)[1]\n",
    "    YCols=np.shape(_Y)[1]\n",
    "    depth = n_steps\n",
    "    \n",
    "    totalRows=np.shape(_X)[0]\n",
    "    # Select random periods (ones where we will always get enough history to go with it)\n",
    "    periodsList = random.sample(range(batchRows+depth, totalRows), _batchRows)\n",
    "    \n",
    "    # Debuigging...\n",
    "    #for i in range(_batchRows -1):\n",
    "    #    periodsList[i+1]=periodsList[i]-1\n",
    "    \n",
    "    # Pre-Initialize batch arrays\n",
    "    batch_x=np.zeros([_batchRows,depth,XCols])\n",
    "    batch_y=np.zeros([_batchRows])\n",
    "\n",
    "    batch_row =0\n",
    "    \n",
    "    for periodPos in periodsList:            \n",
    "        # Log every so often \n",
    "        if (periodPos % 1) == 0: \n",
    "            timeNow =str(datetime.datetime.now())\n",
    "            #print(\"{} Now adding random period {} into batch_row {}. ({}%)\".format(timeNow,idx1,batch_row, round((batch_row/_batchRows)*100,2)))\n",
    "            #logging.info(\"{} Now adding random period {} into batch_row ({}%)\".format(timeNow, idx1,batch_row, round((batch_row/_batchRows)*100,2)))\n",
    "\n",
    "        batch_x[batch_row] = _X[periodPos-depth:periodPos].reshape(1,depth,XCols)\n",
    "        batch_y[batch_row] = _Y[periodPos]\n",
    "        batch_row +=1\n",
    "    return batch_x, batch_y\n",
    "print ('Ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "###           MODEL 1    Train             ###\n",
    "##############################################\n",
    "def trainModel_1(batch_x, batch_y):        \n",
    "    sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "    # Calculate loss & accuracy\n",
    "    loss = sess.run(_cost,feed_dict={x: batch_x, y: batch_y})\n",
    "    acc = sess.run(_accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "    \n",
    "    return loss, acc\n",
    "print('Ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">3. Model Testing Functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Launch the graph\n",
    "def TestPredictions1(_X, _Y, sess, _batchRows = 10, testPeriods = None):\n",
    "    # Training cycle\n",
    "    totalRows=np.shape(_X)[0]\n",
    "    XCols=np.shape(_X)[1]\n",
    "    YCols=_Y\n",
    "    depth = n_steps\n",
    "    \n",
    "    # If no test periods were provided generate your own\n",
    "    if testPeriods is None:\n",
    "        # Select periods where we will always get enough history to go with it\n",
    "        \n",
    "        testPeriods = random.sample(range(batchRows+depth, totalRows), _batchRows)\n",
    "    else:\n",
    "        testPeriods = testPeriods + batchRows+depth-1\n",
    "        _batchRows = len(testPeriods)\n",
    "     \n",
    "    # Pre-Initialize batch arrays\n",
    "    batch_x=np.zeros([_batchRows,depth,XCols])\n",
    "    batch_y=np.zeros([_batchRows])\n",
    "\n",
    "    batch_row =0\n",
    "    for idx1 in testPeriods:            \n",
    "        if (idx1 % 1) == 0: \n",
    "            timeNow =str(datetime.datetime.now())\n",
    "            #print(\"{} Now testing on period {} ({}%)\".format(timeNow,idx1,round((batch_row/_batchRows)*100,2)))\n",
    "            logging.info(\"{} Now testing period {} ({}%)\".format(timeNow, idx1,round((batch_row/_batchRows)*100,2)))\n",
    "\n",
    "        batch_x[batch_row] = _X[idx1-depth:idx1].reshape(1,depth,XCols)\n",
    "        batch_y[batch_row] = _Y[idx1]\n",
    "        batch_row +=1\n",
    "    \n",
    "    print (\"Processed {}\".format(_batchRows))\n",
    "    # Predict for this period\n",
    "    prob = sess.run(_predProb, feed_dict={x: batch_x, y: batch_y})\n",
    "    predictions = sess.run(_pred, feed_dict={x: batch_x, y: batch_y})\n",
    "    \n",
    "    return predictions, batch_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Test hidden periods</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TestHiddenPeriods(hiddenTestPeriods=50, useTestData = False):\n",
    "\n",
    "    print('{} Hidden Periods\\n'.format(hiddenTestPeriods))\n",
    "    print (\"Cell type= {}, learning_rate = {}, Iterations = {}, batch size = {}, Steps = {}, Hidden Layers = {}, Classes = {}\\n\".format(cellType,learning_rate,period_Iterations,batch_size, n_steps ,n_hidden,n_classes))\n",
    "\n",
    "    if useTestData == False:\n",
    "        predictions,labels = TestPredictions1(xTrain,yTrain,sess,numOfPeriods=hiddenTestPeriods)\n",
    "    else:\n",
    "        predictions,labels = TestPredictions1(xTest,yTest,sess,numOfPeriods=hiddenTestPeriods)\n",
    "    \n",
    "    print(np.shape(labels),np.shape(predictions))    \n",
    "    print(metrics.classification_report(labels,predictions))  # Need to feed it yTest not yTest_OneHot here\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "def TrainModel():\n",
    "    counter =0\n",
    "    batch_y=[]\n",
    "    batch_x=[]\n",
    "    \n",
    "    loss=np.zeros([user_iteration*period_Iterations*batch_Iterations])\n",
    "    acc=np.zeros([user_iteration*period_Iterations*batch_Iterations])\n",
    "    \n",
    "    for userCount in range(user_iteration):  # Iterate through user selection\n",
    "        timeNow =str(datetime.datetime.now())\n",
    "\n",
    "        if dummyTest:  # If working on the dummy data then set to user\n",
    "            users = pd.DataFrame(data={'userID': [3]})\n",
    "        else:\n",
    "            users=cc.getUsers(dbPath).sample(1) # Randomly select 1 user\n",
    " \n",
    "        userID = users.iloc[0].userID\n",
    "        timeNow =datetime.datetime.now().strftime('%D %H:%M:%S')\n",
    "        \n",
    "        # Select user data\n",
    "        xTrain, yTrain, xTest, yTest = cc.SelectUserData_TrainTest(dbPath,tblName,fieldList,userIDs=[userID],oneHot=False,periodGranularity=periodGranularity)\n",
    "\n",
    "        print('{} User Iteration {} Random user {} (Total plays {})'.format(timeNow, userCount,userID,sum(yTrain)))\n",
    "        logging.info('{} Now processing random user {}'.format(timeNow, userID))\n",
    "\n",
    "        if xTrain is not None:\n",
    "            for i in range(period_Iterations):\n",
    "                while sum(batch_y) == 0:\n",
    "                    batch_x, batch_y = randomSelectFromData(xTrain, yTrain, _batchRows=batchRows)\n",
    "\n",
    "                for j in range(batch_Iterations):\n",
    "                    loss[counter],acc[counter] = trainModel_1(batch_x,batch_y)\n",
    "                    timeNow =datetime.datetime.now().strftime('%D %H:%M:%S')\n",
    "                    s=\"  User {} Mini-batch {} Iteration {} Loss={:.6f}, Training Accuracy={:.5f}\".format(userCount,i, j, loss[counter], acc[counter])\n",
    "                    print(s)\n",
    "                    logging.info(s)\n",
    "                    counter+=1\n",
    "\n",
    "                \n",
    "                if i % 10 == 0:\n",
    "                    predictions = sess.run(_pred, feed_dict={x: batch_x, y: batch_y})\n",
    "                    logits= sess.run(_logits, feed_dict={x: batch_x, y: batch_y})\n",
    "                    prob= sess.run(_predProb, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "                    print(metrics.classification_report(batch_y,predictions))  # Need to feed it yTest not yTest_OneHot here\n",
    "                    saver = tf.train.Saver()\n",
    "                    saver.save(sess,\"./3_Data/saves/model.ckpt\")\n",
    "                    \n",
    "print('Training completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:green;color:white\">4. ...And action!</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/12/17 13:15:15 User Iteration 0 Random user 78 (Total plays [2617])\n",
      "User 0 Mini-batch 0 Iteration 0 Loss=0.299888, Training Accuracy=0.92000\n",
      "User 0 Mini-batch 0 Iteration 1 Loss=0.322693, Training Accuracy=0.94000\n",
      "User 0 Mini-batch 0 Iteration 2 Loss=0.347542, Training Accuracy=0.81000\n",
      "User 0 Mini-batch 0 Iteration 3 Loss=0.267634, Training Accuracy=0.93000\n",
      "User 0 Mini-batch 0 Iteration 4 Loss=0.241045, Training Accuracy=0.92000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      1.00      0.96        92\n",
      "        1.0       0.00      0.00      0.00         8\n",
      "\n",
      "avg / total       0.85      0.92      0.88       100\n",
      "\n",
      "User 0 Mini-batch 1 Iteration 0 Loss=0.239867, Training Accuracy=0.92000\n",
      "User 0 Mini-batch 1 Iteration 1 Loss=0.218134, Training Accuracy=0.92000\n",
      "User 0 Mini-batch 1 Iteration 2 Loss=0.174601, Training Accuracy=0.92000\n",
      "User 0 Mini-batch 1 Iteration 3 Loss=0.136069, Training Accuracy=0.90000\n",
      "User 0 Mini-batch 1 Iteration 4 Loss=0.138935, Training Accuracy=0.95000\n",
      "08/12/17 13:16:54 User Iteration 1 Random user 52 (Total plays [6224])\n",
      "User 1 Mini-batch 0 Iteration 0 Loss=0.157582, Training Accuracy=0.95000\n",
      "User 1 Mini-batch 0 Iteration 1 Loss=0.145499, Training Accuracy=0.94000\n",
      "User 1 Mini-batch 0 Iteration 2 Loss=0.124851, Training Accuracy=0.93000\n",
      "User 1 Mini-batch 0 Iteration 3 Loss=0.122032, Training Accuracy=0.93000\n",
      "User 1 Mini-batch 0 Iteration 4 Loss=0.131184, Training Accuracy=0.93000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.99      0.96        92\n",
      "        1.0       0.67      0.25      0.36         8\n",
      "\n",
      "avg / total       0.92      0.93      0.92       100\n",
      "\n",
      "User 1 Mini-batch 1 Iteration 0 Loss=0.135967, Training Accuracy=0.92000\n",
      "User 1 Mini-batch 1 Iteration 1 Loss=0.129435, Training Accuracy=0.94000\n",
      "User 1 Mini-batch 1 Iteration 2 Loss=0.116609, Training Accuracy=0.93000\n",
      "User 1 Mini-batch 1 Iteration 3 Loss=0.107529, Training Accuracy=0.94000\n",
      "User 1 Mini-batch 1 Iteration 4 Loss=0.106299, Training Accuracy=0.94000\n",
      "08/12/17 13:18:29 User Iteration 2 Random user 96 (Total plays [2308])\n",
      "User 2 Mini-batch 0 Iteration 0 Loss=0.107441, Training Accuracy=0.94000\n",
      "User 2 Mini-batch 0 Iteration 1 Loss=0.104189, Training Accuracy=0.94000\n",
      "User 2 Mini-batch 0 Iteration 2 Loss=0.096756, Training Accuracy=0.95000\n",
      "User 2 Mini-batch 0 Iteration 3 Loss=0.091240, Training Accuracy=0.96000\n",
      "User 2 Mini-batch 0 Iteration 4 Loss=0.091603, Training Accuracy=0.95000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.98      0.97        92\n",
      "        1.0       0.71      0.62      0.67         8\n",
      "\n",
      "avg / total       0.95      0.95      0.95       100\n",
      "\n",
      "User 2 Mini-batch 1 Iteration 0 Loss=0.094873, Training Accuracy=0.95000\n",
      "User 2 Mini-batch 1 Iteration 1 Loss=0.095665, Training Accuracy=0.94000\n",
      "User 2 Mini-batch 1 Iteration 2 Loss=0.092800, Training Accuracy=0.95000\n",
      "User 2 Mini-batch 1 Iteration 3 Loss=0.089643, Training Accuracy=0.95000\n",
      "User 2 Mini-batch 1 Iteration 4 Loss=0.089017, Training Accuracy=0.96000\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "# Model setup\n",
    "loadFromSave = False\n",
    "user_iteration = 3  # How many iterations of user selection\n",
    "period_Iterations = 2  # How many iterations of random periods selection\n",
    "batchRows = 100   # How many periods to select in each user_iteration\n",
    "batch_Iterations = 5\n",
    "n_steps = 672         # How many time steps (i.e. depth) to have\n",
    "learning_rate = 0.001\n",
    "n_hidden = 250 # hidden layer num of features\n",
    "n_classes = 2  # 2 for one-hot\n",
    "cellType = \"BasicLSTMCell\"  # Choose: TimeFreqLSTMCell BasicLSTMCell\n",
    "fieldList=\"UserID, t, HrsFrom5pm, isSun,isMon,isTue,isWed,isThu,isFri,isSat, t1,t2,t3,t4,t5,t10,t12hrs,t23_5hrs,t24hrs,t24_5hrs,t1wk,t2wks,t3wks,t4wks\"\n",
    "tblName='tblTimeSeriesData'\n",
    "\n",
    "\n",
    "#ResetModel()\n",
    "#initializeModel()\n",
    "TrainModel()\n",
    "print ('Ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Test</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing held out users\n",
      "User 1 of 10 Av loss 0.321 Av acc 0.898\n",
      "User 2 of 10 Av loss 0.692 Av acc 0.886\n",
      "User 3 of 10 Av loss 0.437 Av acc 0.914\n",
      "User 4 of 10 Av loss 1.681 Av acc 0.759\n",
      "User 5 of 10 Av loss 0.391 Av acc 0.889\n",
      "User 6 of 10 Av loss 0.542 Av acc 0.882\n",
      "User 7 of 10 Av loss 0.672 Av acc 0.832\n",
      "User 8 of 10 Av loss 0.212 Av acc 0.939\n",
      "User 9 of 10 Av loss 4.043 Av acc 0.549\n",
      "User 10 of 10 Av loss 0.78 Av acc 0.87\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.96      0.91      8726\n",
      "        1.0       0.11      0.03      0.05      1274\n",
      "\n",
      "avg / total       0.77      0.84      0.80     10000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.96      0.91      8726\n",
      "        1.0       0.11      0.03      0.05      1274\n",
      "\n",
      "avg / total       0.77      0.84      0.80     10000\n",
      "\n",
      "Testing complete\n"
     ]
    }
   ],
   "source": [
    "def TestModel():\n",
    "    print('Testing held out users')\n",
    "    totalLabels = []\n",
    "    totalPred = []\n",
    "    avLoss =0\n",
    "    avAcc =0\n",
    "    users=cc.getUsers(dbPath,testUserEquals = 1)  # Get all test users\n",
    "\n",
    "    usrCount = 1\n",
    "    for usr in users.itertuples(): # For each test user    \n",
    "        # Select all data for each user\n",
    "        xTest, yTest = cc.SelectUserData_All(dbPath,tblName,fieldList,userIDs=[usr.userID],oneHot=False,periodGranularity=periodGranularity)\n",
    "        \n",
    "        if xTest is not None:\n",
    "            for i in range(10):  # Select a random batch, 10 times\n",
    "                batch_x, batch_y = randomSelectFromData(xTest, yTest, _batchRows=batchRows)\n",
    "\n",
    "                p = sess.run(_pred, feed_dict={x: batch_x, y: batch_y})\n",
    "                p =batch_x['t1']\n",
    "                loss = sess.run(_cost,feed_dict={x: batch_x, y: batch_y})\n",
    "                acc = sess.run(_accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "                avLoss+=loss\n",
    "                avAcc+=acc\n",
    "\n",
    "                if totalLabels ==[]:\n",
    "                    totalLabels = batch_y\n",
    "                    totalPred = p\n",
    "\n",
    "                else:\n",
    "                    totalLabels = np.append(totalLabels,batch_y)\n",
    "                    totalPred = np.append(totalPred,p)\n",
    "        print('User {} of {} Av loss {} Av acc {}'.format(usrCount , len(users), np.round(avLoss/10,3), np.round(avAcc/10,3)))\n",
    "        avLoss=0\n",
    "        avAcc = 0\n",
    "        usrCount+=1                \n",
    "\n",
    "    print('Overall results:')\n",
    "    totalPredBaseline = xTest[:,8]\n",
    "    print(metrics.classification_report(totalLabels,totalPred))  # Need to feed it yTest not yTest_OneHot here\n",
    "    print(metrics.classification_report(totalLabels,totalPred))  # Need to feed it yTest not yTest_OneHot here\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess,\"./3_Data/saves/model.ckpt\")\n",
    "    print('Testing complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing held out users\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.97      0.97    390773\n",
      "        1.0       0.77      0.77      0.77     43696\n",
      "\n",
      "avg / total       0.95      0.95      0.95    434469\n",
      "\n",
      "Testing complete\n"
     ]
    }
   ],
   "source": [
    "def BaselineTest():\n",
    "    print('Testing held out users')\n",
    "    totalLabels = []\n",
    "    totalPred = []\n",
    "    users=cc.getUsers(dbPath,testUserEquals = 1)  # Get all test users\n",
    "\n",
    "    usrCount = 1\n",
    "    for usr in users.itertuples(): # For each test user    \n",
    "        # Select all data for each user\n",
    "        xTest, yTest = cc.SelectUserData_All(dbPath,tblName,fieldList,userIDs=[usr.userID],oneHot=False,periodGranularity=periodGranularity)\n",
    "        totalLabels = np.append(totalLabels,yTest)\n",
    "        totalPred = np.append(totalPred,xTest[:,8])\n",
    "    \n",
    "    print(metrics.classification_report(totalLabels,totalPred))  # Need to feed it yTest not yTest_OneHot here\n",
    "    print('Testing complete')\n",
    "BaselineTest()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
