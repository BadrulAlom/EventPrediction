{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-ce4878cea1be>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-ce4878cea1be>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    <h1 align=\"center\" style=\"background-color:#616161;color:white\">Next play prediction using Logistic Regression</h1>\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<h1 align=\"center\" style=\"background-color:#616161;color:white\">Next play prediction using Logistic Regression</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">0. Setup</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Input Parameters</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PeriodGranularity = 30 # E.g. 15, 30, 60\n",
    "# Train / Test split\n",
    "newUsers = 10   # Num of randomly selected users to separate out of eval 2\n",
    "rndPeriods = 3 # Num of random periods from each use to select\n",
    "rndPeriodsLength = int(60/PeriodGranularity) * 24 * 7 * 4     # How long the random test period should cover\n",
    "\n",
    "# Root path\n",
    "root = \"C:/DS/Github/MusicRecommendation\"  # BA, Windows\n",
    "#root = \"/home/badrul/Documents/github/MusicRecommendation\" # BA, Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Import Libraries</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>Standard code used in every page. Not all of these libraries are used here.</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.debugger import Tracer    # Used for debugging\n",
    "import logging\n",
    "\n",
    "# File and database management\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "# Date/Time\n",
    "import datetime\n",
    "import time\n",
    "#from datetime import timedelta # Deprecated\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt             # Quick\n",
    "%matplotlib inline\n",
    "\n",
    "# Data science (comment out if not needed)\n",
    "#from sklearn.manifold import TSNE\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Misc\n",
    "import random\n",
    "\n",
    "#-------------- Custom Libs -----------------#\n",
    "os.chdir(root)\n",
    "\n",
    "# Import the codebase module\n",
    "fPath = root + \"/1_codemodule\"\n",
    "if fPath not in sys.path: sys.path.append(fPath)\n",
    "\n",
    "# Custom Libs\n",
    "import coreCode as cc\n",
    "import lastfmCode as fm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Declare Functions</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Source: https://beckernick.github.io/logistic-regression-from-scratch/\n",
    "        \n",
    "# Link function\n",
    "def sigmoid(scores):\n",
    "    return 1 / (1 + np.exp(-scores))\n",
    "\n",
    "def log_likelihood(features, target, weights):\n",
    "    scores = np.dot(features, weights)\n",
    "    ll = np.sum( target*scores - np.log(1 + np.exp(scores)) )\n",
    "    return ll\n",
    "\n",
    "def MyLogisticRegression(features, target, num_steps, learning_rate, add_intercept = False):\n",
    "    if add_intercept:\n",
    "        intercept = np.ones((features.shape[0], 1))\n",
    "        features = np.hstack((intercept, features))\n",
    "        \n",
    "    weights = np.zeros(features.shape[1])\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        scores = np.dot(features, weights)\n",
    "        predictions = sigmoid(scores)\n",
    "\n",
    "        # Update weights with gradient\n",
    "        output_error_signal = target - predictions\n",
    "        gradient = np.dot(features.T, output_error_signal)\n",
    "        weights += learning_rate * gradient\n",
    "        \n",
    "        # Print log-likelihood every so often\n",
    "        if step % 10000 == 0:\n",
    "            print (log_likelihood(features, target, weights))\n",
    "        \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Load settings</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "settingsDict =  cc.loadSettings()\n",
    "dbPath = root + settingsDict['mainDbPath']\n",
    "fmSimilarDbPath = root + settingsDict['fmSimilarDbPath']\n",
    "fmTagsDbPath = root + settingsDict['fmTagsDbPath']\n",
    "trackMetaDbPath = root + settingsDict['trackmetadata']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Other setup</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>None</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">1. Get train & test data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we go through every user, one at a time, and randomly select 2 sections of the dataset to use as test data. The code here could be improved to make it any n cut-off points. \n",
    "\n",
    "More importantly, we ensure that each test period covers an entire months worth of data in order to reduce pollution between training and test data. (So first pick cut-off points, then move forward by a month to get the range of the test data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Get train and test data</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "def getTrainAndTestData():\n",
    "    con = sqlite3.connect(dbPath)\n",
    "    c = con.cursor()\n",
    "\n",
    "    # Get list of UserIDs \n",
    "    trainUsers = pd.read_sql_query(\"Select UserID from tblUsers Where tblUsers.TestUser = 0\",con)\n",
    "\n",
    "    fieldList=\"t, UserID, HrsFrom6pm, isSun,isMon,isTue,isWed,isThu,isFri,isSat,t1,t2,t3,t4,t5,t10,t12hrs,t24hrs,t1wk,t2wks,t3wks,t4wks\"\n",
    "    trainDf=pd.DataFrame(columns=[fieldList])  # Create an emmpty df\n",
    "    testDf=pd.DataFrame(columns=[fieldList])  # Create an emmpty df\n",
    "    periodsInAMonth=int(60/PeriodGranularity)*24*7*4\n",
    "\n",
    "    totalRows=0\n",
    "    \n",
    "    for user in trainUsers.itertuples():\n",
    "        # Get training dataset\n",
    "        SqlStr=\"SELECT {} from tblTimeSeriesData where UserID = {}\".format(fieldList,user.userID)\n",
    "        df = pd.read_sql_query(SqlStr, con)\n",
    "        totalRows += len(df)\n",
    "    \n",
    "        # Cut-off 1\n",
    "        k = random.randint(periodsInAMonth, len(df))\n",
    "        #Tracer()()  -- for debugging purposes\n",
    "        testDf = testDf.append(df.iloc[k:k+periodsInAMonth])[df.columns.tolist()]\n",
    "\n",
    "        tmp = df.drop(df.index[k:k+periodsInAMonth])\n",
    "\n",
    "        # Cut-off 2\n",
    "        k = random.randint(periodsInAMonth, len(tmp))\n",
    "        testDf = testDf.append(tmp.iloc[k:k+periodsInAMonth])[df.columns.tolist()]\n",
    "        trainDf = trainDf.append(tmp.drop(tmp.index[k:k+periodsInAMonth]))[df.columns.tolist()]\n",
    "\n",
    "    if len(trainDf)+len(testDf) == totalRows:\n",
    "        print('Ok')\n",
    "    else:\n",
    "        print(\"Incorrect. Total Rows = {}. TestDf+TrainDf rows = {}+{}={}\".format(totalRows,len(testDf),len(trainDf),len(testDf)+len(trainDf)))\n",
    "        \n",
    "    return trainDf, testDf\n",
    "\n",
    "trainDf,testDf = getTrainAndTestData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">2. Gaussian Process Classification using an RBF Kernel</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-616fb2ac867c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# Put the result into a color plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DS\\Installs\\Anaconda3\\lib\\site-packages\\numpy\\lib\\index_tricks.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    336\u001b[0m                 \u001b[0mobjs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobjs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_retval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAAEzCAYAAACBqAUFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuAXcnPAB/gEDECxJTfZXTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dca4e5e710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = trainDf.drop(['t','UserID'], 1).values\n",
    "X=X[0:100]\n",
    "y = trainDf['t'].values.astype(int) \n",
    "y=y[0:100]\n",
    "\n",
    "xx= testDf.drop(['t','UserID'], 1).values\n",
    "yy = testDf['t'].values.astype(int)\n",
    "yy=yy.reshape(len(yy),1)\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "# import some data to play with\n",
    "#iris = datasets.load_iris()\n",
    "#X = iris.data[:, :2]  # we only take the first two features.\n",
    "#y = np.array(iris.target, dtype=int)\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "titles = [\"Isotropic RBF\", \"Anisotropic RBF\"]\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "kernel = 1.0 * RBF([1.0]*20)\n",
    "gpc_rbf_isotropic = GaussianProcessClassifier(kernel=kernel).fit(X, y)\n",
    "kernel = 1.0 * RBF([1.0]*20)\n",
    "gpc_rbf_anisotropic = GaussianProcessClassifier(kernel=kernel).fit(X, y)\n",
    "\n",
    "\n",
    "for i, clf in enumerate((gpc_rbf_isotropic, gpc_rbf_anisotropic)):\n",
    "    # Plot the predicted probabilities. For that, we will assign a color to\n",
    "    # each point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    plt.subplot(1, 20, i + 1)\n",
    "\n",
    "    Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape((xx.shape[0], xx.shape[1], 3))\n",
    "    plt.imshow(Z, extent=(x_min, x_max, y_min, y_max), origin=\"lower\")\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=np.array([\"r\", \"g\", \"b\"])[y])\n",
    "    plt.xlabel('Sepal length')\n",
    "    plt.ylabel('Sepal width')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(\"%s, LML: %.3f\" %\n",
    "              (titles[i], clf.log_marginal_likelihood(clf.kernel_.theta)))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1075200,), (53760,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.c_[xx.ravel(), yy.ravel()] # Translates slice objects to concatenation along the second axis.\n",
    "xx.ravel().shape,yy.ravel().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">3. Logistic Regression coded by hand</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = trainDf.drop(['t','UserID'], 1).values\n",
    "Y = trainDf['t'].values.astype(int) \n",
    "\n",
    "# fit a logistic regression model to the data\n",
    "weights = MyLogisticRegression(X, Y,\n",
    "                     num_steps = 300000, learning_rate = 5e-5, add_intercept=True)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
