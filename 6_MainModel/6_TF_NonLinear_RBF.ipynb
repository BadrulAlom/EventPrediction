{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\" style=\"background-color:#616161;color:white\">Nonlinear SVM Example in Tensorflow</h1>\n",
    "\n",
    "Adapted from: https://github.com/nfmcclure/tensorflow_cookbook/blob/master/04_Support_Vector_Machines/05_Implementing_Nonlinear_SVMs/05_nonlinear_svm.ipynb\n",
    "\n",
    "This function wll illustrate how to implement the gaussian kernel on the iris dataset.\n",
    "\n",
    "Gaussian Kernel:\n",
    "\n",
    "$$K(x_{1}, x_{2}) = exp\\left(-\\gamma * (x_{1} - x_{2})^{2}\\right)$$\n",
    "\n",
    "We start by loading the necessary libraries and resetting the computational graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">0. Setup</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Input Parameters</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PeriodGranularity = 30 # E.g. 15, 30, 60\n",
    "# Train / Test split\n",
    "newUsers = 10   # Num of randomly selected users to separate out of eval 2\n",
    "rndPeriods = 3 # Num of random periods from each use to select\n",
    "rndPeriodsLength = int(60/PeriodGranularity) * 24 * 7 * 4     # How long the random test period should cover\n",
    "\n",
    "# Root path\n",
    "#root = \"C:/DS/Github/MusicRecommendation\"  # BA, Windows\n",
    "root = \"/home/badrul/Documents/git/MusicRecommendation\" # BA, Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Common Libraries</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.debugger import Tracer    # Used for debugging\n",
    "import logging\n",
    "\n",
    "# File and database management\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "# Date/Time\n",
    "import datetime\n",
    "import time\n",
    "#from datetime import timedelta # Deprecated\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt             # Quick\n",
    "%matplotlib inline\n",
    "\n",
    "# Misc\n",
    "import random\n",
    "\n",
    "#-------------- Custom Libs -----------------#\n",
    "os.chdir(root)\n",
    "\n",
    "# Import the codebase module\n",
    "fPath = root + \"/1_codemodule\"\n",
    "if fPath not in sys.path: sys.path.append(fPath)\n",
    "\n",
    "# Custom Libs\n",
    "import coreCode as cc\n",
    "import lastfmCode as fm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Page Specific Libraries</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data science (comment out if not needed)\n",
    "#from sklearn.manifold import TSNE\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Declare Functions</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Load settings</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settingsDict =  cc.loadSettings()\n",
    "dbPath = root + settingsDict['mainDbPath']\n",
    "fmSimilarDbPath = root + settingsDict['fmSimilarDbPath']\n",
    "fmTagsDbPath = root + settingsDict['fmTagsDbPath']\n",
    "trackMetaDbPath = root + settingsDict['trackmetadata']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a graph session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">1. Load data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "def getTrainAndTestData():\n",
    "    con = sqlite3.connect(dbPath)\n",
    "    c = con.cursor()\n",
    "\n",
    "    # Get list of UserIDs \n",
    "    trainUsers = pd.read_sql_query(\"Select UserID from tblUsers Where tblUsers.TestUser = 0\",con)\n",
    "\n",
    "    fieldList=\"t, UserID, HrsFrom6pm, isSun,isMon,isTue,isWed,isThu,isFri,isSat,t1,t2,t3,t4,t5,t10,t12hrs,t24hrs,t1wk,t2wks,t3wks,t4wks\"\n",
    "    trainDf=pd.DataFrame(columns=[fieldList])  # Create an emmpty df\n",
    "    testDf=pd.DataFrame(columns=[fieldList])  # Create an emmpty df\n",
    "    periodsInAMonth=int(60/PeriodGranularity)*24*7*4\n",
    "\n",
    "    totalRows=0\n",
    "    \n",
    "    for user in trainUsers.itertuples():\n",
    "        # Get training dataset\n",
    "        SqlStr=\"SELECT {} from tblTimeSeriesData where UserID = {}\".format(fieldList,user.userID)\n",
    "        df = pd.read_sql_query(SqlStr, con)\n",
    "        totalRows += len(df)\n",
    "    \n",
    "        # Cut-off 1\n",
    "        k = random.randint(periodsInAMonth, len(df))\n",
    "        #Tracer()()  -- for debugging purposes\n",
    "        testDf = testDf.append(df.iloc[k:k+periodsInAMonth])[df.columns.tolist()]\n",
    "\n",
    "        tmp = df.drop(df.index[k:k+periodsInAMonth])\n",
    "\n",
    "        # Cut-off 2\n",
    "        k = random.randint(periodsInAMonth, len(tmp))\n",
    "        testDf = testDf.append(tmp.iloc[k:k+periodsInAMonth])[df.columns.tolist()]\n",
    "        trainDf = trainDf.append(tmp.drop(tmp.index[k:k+periodsInAMonth]))[df.columns.tolist()]\n",
    "\n",
    "    if len(trainDf)+len(testDf) == totalRows:\n",
    "        print('Ok')\n",
    "    else:\n",
    "        print(\"Incorrect. Total Rows = {}. TestDf+TrainDf rows = {}+{}={}\".format(totalRows,len(testDf),len(trainDf),len(testDf)+len(trainDf)))\n",
    "        \n",
    "    return trainDf, testDf\n",
    "\n",
    "trainDf,testDf = getTrainAndTestData()\n",
    "\n",
    "x_vals = trainDf.drop(['t','UserID'], 1).values\n",
    "y_vals = trainDf['t'].values.astype(int) \n",
    "# Change the 0's to -1\n",
    "y_vals = np.array([1 if y==1 else -1 for y in y_vals])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Confirm dimensions</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((937519, 20), (937519,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numOfFeatures = np.shape(x_vals)[1]\n",
    "np.shape(x_vals),np.shape(y_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#616161;color:white\">2. Define Model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Model Parameters</div>\n",
    "\n",
    "We now declare our batch size, placeholders, and the fitted b-value for the SVM kernel.  Note that we will create a separate placeholder to feed in the prediction grid for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare batch size\n",
    "batch_size = 1000\n",
    "\n",
    "# Initialize placeholders within the tf graph\n",
    "x_data = tf.placeholder(shape=[None, numOfFeatures], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "prediction_grid = tf.placeholder(shape=[None, numOfFeatures], dtype=tf.float32)\n",
    "\n",
    "# Create variables for svm within the tf graph\n",
    "b = tf.Variable(tf.random_normal(shape=[1,batch_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Define Kernel</div>\n",
    "\n",
    "We create the gaussian (RBF) kernel that is used to transform the data points into a higher dimensional space.\n",
    "\n",
    "The Kernel of two points, $x$ and $x'$ is given as\n",
    "\n",
    "$$K(x, x')=exp\\left(-\\gamma|| x-x' ||^{2}\\right)$$\n",
    "\n",
    "For $\\gamma$ very small, the kernel is very wide, and vice-versa for large $\\gamma$ values.  This means that large $\\gamma$ leads to high bias and low variance models.\n",
    "\n",
    "If we have a vector of points, $x$ of size (batch_size, 2), then our kernel calculation becomes\n",
    "\n",
    "$$K(\\textbf{x})=exp\\left( -\\gamma \\textbf{x} \\cdot \\textbf{x}^{T} \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the formula\n",
    "gamma = tf.constant(-1.0) # Gamma constant as a negative 1\n",
    "sq_vec = tf.multiply(2., tf.matmul(x_data, tf.transpose(x_data)))  # (x*x^T)*(x*x^T)\n",
    "my_kernel = tf.exp(tf.multiply(gamma, tf.abs(sq_vec)))  # exp(gamma*sq_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Define Loss function</div>\n",
    "\n",
    "Here, the SVM loss is given by two terms, The first term is the sum of the $b$ matrix\n",
    "\n",
    "$$\\sum\\textbf{b}$$\n",
    "\n",
    "and the second term is \n",
    "\n",
    "$$\\sum\\left(K\\cdot||\\textbf{b}||^{2}||\\textbf{y}||^{2}\\right)$$\n",
    "\n",
    "We finally tell TensorFlow to maximize the loss by minimizing the negative:  (The following is a horribly abbreviated version of the dual problem)\n",
    "\n",
    "$$-\\left(\\sum\\textbf{b} - \\sum\\left(K\\cdot||\\textbf{b}||^{2}||\\textbf{y}||^{2}\\right)\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute SVM loss\n",
    "first_term = tf.reduce_sum(b)   # without the axis param this is a straifghtforward sum\n",
    "bsq = tf.matmul(tf.transpose(b), b)    # b^2\n",
    "ysq = tf.matmul(y_target, tf.transpose(y_target))  # y^2\n",
    "second_term = tf.reduce_sum(tf.multiply(my_kernel, tf.multiply(bsq, ysq)))\n",
    "loss = tf.negative(tf.subtract(first_term, second_term))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#white; color:#008000; font-family: 'Courier New, Monospace;font-weight: bold\">Define Prediction kernel</div>\n",
    "\n",
    "Now we do the exact same thing as above for the prediction points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gaussian (RBF) prediction kernel\n",
    "rA = tf.reshape(tf.reduce_sum(tf.square(x_data), 1),[-1,1])\n",
    "rB = tf.reshape(tf.reduce_sum(tf.square(prediction_grid), 1),[-1,1])\n",
    "pred_sq_dist = tf.add(tf.subtract(rA, tf.multiply(2., tf.matmul(x_data, tf.transpose(prediction_grid)))), tf.transpose(rB))\n",
    "pred_kernel = tf.exp(tf.multiply(gamma, tf.abs(pred_sq_dist)))\n",
    "\n",
    "prediction_output = tf.matmul(tf.multiply(tf.transpose(y_target),b), pred_kernel)\n",
    "prediction = tf.sign(prediction_output-tf.reduce_mean(prediction_output))\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.squeeze(prediction), tf.squeeze(y_target)), tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Badrul's notes</b>:<br>\n",
    "This is a good reference: http://www.robots.ox.ac.uk/~az/lectures/ml/lect3.pdf\n",
    "$$x = test data$$\n",
    "$$x_i = train data$$\n",
    "$$rA = x_i^2$$\n",
    "$$rB=x^2$$\n",
    "$$\\gamma ||(x_i^2 -(x_i  x)^2 + x^2)||$$\n",
    "\n",
    "Note following how this is 'the exact same thing as above' or how it relates to the RBF formulas I see in the pdf ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Method\n",
    "\n",
    "We declare our gradient descent optimizer and intialize our model variables (`b`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare optimizer\n",
    "my_opt = tf.train.GradientDescentOptimizer(0.01)\n",
    "train_step = my_opt.minimize(loss)\n",
    "\n",
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Classification!\n",
    "\n",
    "We iterate through the training for 300 iterations. We will output the loss every 300 iterations. One thing to remember about sess is that the first parameter, in this case 'loss' is simply referring to the variable called loss defined earlier - which you can think of as defining a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #300\n",
      "Loss = -1.3565e+11\n",
      "Step #600\n",
      "Loss = -1.85351e+20\n",
      "Step #900\n",
      "Loss = -3.57153e+28\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "loss_vec = []\n",
    "batch_accuracy = []\n",
    "for i in range(1000):\n",
    "    rand_index = np.random.choice(len(x_vals), size=batch_size)\n",
    "    rand_x = x_vals[rand_index]\n",
    "    rand_y = np.transpose([y_vals[rand_index]])\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    \n",
    "    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    loss_vec.append(temp_loss)\n",
    "    \n",
    "    acc_temp = sess.run(accuracy, feed_dict={x_data: rand_x,\n",
    "                                             y_target: rand_y,\n",
    "                                             prediction_grid:rand_x})\n",
    "    batch_accuracy.append(acc_temp)\n",
    "    \n",
    "    if (i+1)%300==0:\n",
    "        print('Step #' + str(i+1))\n",
    "        print('Loss = ' + str(temp_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.77399999,\n",
       " 0.62699997,\n",
       " 0.458,\n",
       " 0.31099999,\n",
       " 0.616,\n",
       " 0.73199999,\n",
       " 0.611,\n",
       " 0.458,\n",
       " 0.111,\n",
       " 0.41800001]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last 10 accuracy scores\n",
    "batch_accuracy[990:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55304, 20), (55304,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data\n",
    "x_test= testDf.drop(['t','UserID'], 1).values\n",
    "y_test = testDf['t'].values.astype(int)\n",
    "y_test=y_test.reshape(len(y_test),1)\n",
    "y_test = np.array([1 if y==1 else -1 for y in y_test])\n",
    "np.shape(x_test), np.shape( y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate the predictions on our test points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[test_predictions] = sess.run(prediction, feed_dict={x_data: rand_x,\n",
    "                                                     y_target: rand_y,\n",
    "                                                     prediction_grid: x_test})\n",
    "#test_predictions = test_predictions.reshape(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ..., -1., -1., -1.], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the test points together with the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.86      0.44      0.58     50236\n",
      "          1       0.05      0.30      0.09      5068\n",
      "\n",
      "avg / total       0.79      0.43      0.54     55304\n",
      "\n",
      "[[22089 28147]\n",
      " [ 3566  1502]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,test_predictions))\n",
    "print(metrics.confusion_matrix(y_test,test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
